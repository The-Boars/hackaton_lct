{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57024b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-23 17:21:53.233 INFO in 'deeppavlov.core.data.utils'['utils'] at line 97: Downloading from http://files.deeppavlov.ai/v1/ner/ner_rus_bert_coll3_torch.tar.gz to C:\\Users\\lexan\\.deeppavlov\\models\\ner_rus_bert_coll3_torch.tar.gz\n",
      "100%|██████████| 1.44G/1.44G [02:20<00:00, 10.2MB/s]\n",
      "2025-09-23 17:24:14.675 INFO in 'deeppavlov.core.data.utils'['utils'] at line 284: Extracting C:\\Users\\lexan\\.deeppavlov\\models\\ner_rus_bert_coll3_torch.tar.gz archive into C:\\Users\\lexan\\.deeppavlov\\models\\ner_rus_bert_coll3_torch\n",
      "c:\\Users\\lexan\\miniconda3\\envs\\dp310\\lib\\site-packages\\huggingface_hub\\file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from deeppavlov import build_model\n",
    "\n",
    "ner_model = build_model('ner_collection3_bert', download=True, install=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cebaef7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~/.deeppavlov/downloads/collection3/\n"
     ]
    }
   ],
   "source": [
    "from deeppavlov import train_model, build_model \n",
    "from deeppavlov.core.commands.utils import parse_config\n",
    "\n",
    "PROJECT_DIR = '..'\n",
    "\n",
    "model_config = parse_config('ner_collection3_bert')\n",
    "\n",
    "# dataset that the model was trained on\n",
    "print(model_config['dataset_reader']['data_path'])\n",
    "\n",
    "model_config['dataset_reader']['data_path'] = PROJECT_DIR + '/datasets/conll/'\n",
    "\n",
    "del model_config['metadata']['download']\n",
    "\n",
    "model_config['metadata']['variables']['MODEL_PATH'] = PROJECT_DIR + '/models'\n",
    "\n",
    "model_config['chainer']['pipe'][1]['save_path'] = PROJECT_DIR + '/models/tag.dict'\n",
    "model_config['chainer']['pipe'][1]['load_path'] = PROJECT_DIR + '/models/tag.dict'\n",
    "\n",
    "model_config['chainer']['pipe'][2]['save_path'] = PROJECT_DIR + '/models'\n",
    "model_config['chainer']['pipe'][2]['load_path'] = PROJECT_DIR + '/models'\n",
    "\n",
    "model_config['train']['batch_size'] = 200\n",
    "\n",
    "model_config['train']['log_every_n_batches'] = 20\n",
    "model_config['train']['val_every_n_batches'] = 20\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecd27e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-24 10:54:52.180 WARNING in 'deeppavlov.core.trainers.fit_trainer'['fit_trainer'] at line 66: TorchTrainer got additional init parameters ['pytest_max_batches', 'pytest_batch_size'] that will be ignored:\n",
      "c:\\Users\\lexan\\miniconda3\\envs\\dp310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\lexan\\miniconda3\\envs\\dp310\\lib\\site-packages\\huggingface_hub\\file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "2025-09-24 10:54:54.825 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 104: [saving vocabulary to C:\\Users\\lexan\\OneDrive\\Documents\\hackaton_lct\\models\\tag.dict]\n",
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2025-09-24 10:54:56.205 WARNING in 'deeppavlov.core.models.torch_model'['torch_model'] at line 151: Init from scratch. Load path C:\\Users\\lexan\\OneDrive\\Documents\\hackaton_lct\\models.pth.tar does not exist.\n",
      "25it [00:01, 15.57it/s]\n",
      "2025-09-24 10:54:57.857 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 198: Initial best ner_f1 of 13.4663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 4905, \"metrics\": {\"ner_f1\": 13.4663, \"ner_token_f1\": 20.9898}, \"time_spent\": \"0:00:02\", \"epochs_done\": 0, \"batches_seen\": 0, \"train_examples_seen\": 0, \"impatience\": 0, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 24.09it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 200, \"metrics\": {\"ner_f1\": 53.0466, \"ner_token_f1\": 73.2673}, \"time_spent\": \"0:00:04\", \"epochs_done\": 0, \"batches_seen\": 20, \"train_examples_seen\": 4000, \"loss\": 1.1314354538917542}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "25it [00:00, 26.63it/s]\n",
      "2025-09-24 10:55:01.123 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 from 13.4663 to 54.4487\n",
      "2025-09-24 10:55:01.123 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2025-09-24 10:55:01.124 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 175: Saving model to C:\\Users\\lexan\\OneDrive\\Documents\\hackaton_lct\\models.pth.tar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 4905, \"metrics\": {\"ner_f1\": 54.4487, \"ner_token_f1\": 73.2132}, \"time_spent\": \"0:00:05\", \"epochs_done\": 0, \"batches_seen\": 20, \"train_examples_seen\": 4000, \"impatience\": 0, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 23.52it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 200, \"metrics\": {\"ner_f1\": 77.551, \"ner_token_f1\": 84.1912}, \"time_spent\": \"0:00:10\", \"epochs_done\": 0, \"batches_seen\": 40, \"train_examples_seen\": 8000, \"loss\": 0.37277946472167967}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "25it [00:01, 24.86it/s]\n",
      "2025-09-24 10:55:06.776 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 from 54.4487 to 78.0545\n",
      "2025-09-24 10:55:06.777 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2025-09-24 10:55:06.777 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 175: Saving model to C:\\Users\\lexan\\OneDrive\\Documents\\hackaton_lct\\models.pth.tar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 4905, \"metrics\": {\"ner_f1\": 78.0545, \"ner_token_f1\": 86.2954}, \"time_spent\": \"0:00:11\", \"epochs_done\": 0, \"batches_seen\": 40, \"train_examples_seen\": 8000, \"impatience\": 0, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 25.00it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 200, \"metrics\": {\"ner_f1\": 79.7495, \"ner_token_f1\": 84.3066}, \"time_spent\": \"0:00:16\", \"epochs_done\": 0, \"batches_seen\": 60, \"train_examples_seen\": 12000, \"loss\": 0.2215816542506218}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "25it [00:00, 26.88it/s]\n",
      "2025-09-24 10:55:12.570 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 from 78.0545 to 84.5673\n",
      "2025-09-24 10:55:12.571 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2025-09-24 10:55:12.571 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 175: Saving model to C:\\Users\\lexan\\OneDrive\\Documents\\hackaton_lct\\models.pth.tar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 4905, \"metrics\": {\"ner_f1\": 84.5673, \"ner_token_f1\": 88.8095}, \"time_spent\": \"0:00:17\", \"epochs_done\": 0, \"batches_seen\": 60, \"train_examples_seen\": 12000, \"impatience\": 0, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 27.03it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 200, \"metrics\": {\"ner_f1\": 91.4894, \"ner_token_f1\": 93.5361}, \"time_spent\": \"0:00:22\", \"epochs_done\": 0, \"batches_seen\": 80, \"train_examples_seen\": 16000, \"loss\": 0.16946877613663675}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "25it [00:00, 25.52it/s]\n",
      "2025-09-24 10:55:18.246 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 from 84.5673 to 86.5115\n",
      "2025-09-24 10:55:18.247 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2025-09-24 10:55:18.248 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 175: Saving model to C:\\Users\\lexan\\OneDrive\\Documents\\hackaton_lct\\models.pth.tar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 4905, \"metrics\": {\"ner_f1\": 86.5115, \"ner_token_f1\": 90.5514}, \"time_spent\": \"0:00:23\", \"epochs_done\": 0, \"batches_seen\": 80, \"train_examples_seen\": 16000, \"impatience\": 0, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "96it [00:25,  3.74it/s]\n",
      "1it [00:00, 25.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 200, \"metrics\": {\"ner_f1\": 88.651, \"ner_token_f1\": 91.3958}, \"time_spent\": \"0:00:28\", \"epochs_done\": 1, \"batches_seen\": 100, \"train_examples_seen\": 19875, \"loss\": 0.14161256551742554}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "25it [00:01, 24.62it/s]\n",
      "2025-09-24 10:55:25.66 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 from 86.5115 to 88.2262\n",
      "2025-09-24 10:55:25.66 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2025-09-24 10:55:25.67 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 175: Saving model to C:\\Users\\lexan\\OneDrive\\Documents\\hackaton_lct\\models.pth.tar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 4905, \"metrics\": {\"ner_f1\": 88.2262, \"ner_token_f1\": 91.5262}, \"time_spent\": \"0:00:29\", \"epochs_done\": 1, \"batches_seen\": 100, \"train_examples_seen\": 19875, \"impatience\": 0, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 27.76it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 200, \"metrics\": {\"ner_f1\": 90.9474, \"ner_token_f1\": 92.3933}, \"time_spent\": \"0:00:34\", \"epochs_done\": 1, \"batches_seen\": 120, \"train_examples_seen\": 23875, \"loss\": 0.12089379392564296}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "25it [00:00, 25.76it/s]\n",
      "2025-09-24 10:55:30.802 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 from 88.2262 to 89.6712\n",
      "2025-09-24 10:55:30.802 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2025-09-24 10:55:30.803 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 175: Saving model to C:\\Users\\lexan\\OneDrive\\Documents\\hackaton_lct\\models.pth.tar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 4905, \"metrics\": {\"ner_f1\": 89.6712, \"ner_token_f1\": 92.3909}, \"time_spent\": \"0:00:35\", \"epochs_done\": 1, \"batches_seen\": 120, \"train_examples_seen\": 23875, \"impatience\": 0, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 26.66it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 200, \"metrics\": {\"ner_f1\": 91.0973, \"ner_token_f1\": 92.8058}, \"time_spent\": \"0:00:40\", \"epochs_done\": 1, \"batches_seen\": 140, \"train_examples_seen\": 27875, \"loss\": 0.10973363593220711}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "25it [00:00, 25.59it/s]\n",
      "2025-09-24 10:55:36.780 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 from 89.6712 to 90.1206\n",
      "2025-09-24 10:55:36.780 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2025-09-24 10:55:36.781 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 175: Saving model to C:\\Users\\lexan\\OneDrive\\Documents\\hackaton_lct\\models.pth.tar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 4905, \"metrics\": {\"ner_f1\": 90.1206, \"ner_token_f1\": 92.9638}, \"time_spent\": \"0:00:41\", \"epochs_done\": 1, \"batches_seen\": 140, \"train_examples_seen\": 27875, \"impatience\": 0, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 21.04it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 200, \"metrics\": {\"ner_f1\": 91.3481, \"ner_token_f1\": 94.7735}, \"time_spent\": \"0:00:46\", \"epochs_done\": 1, \"batches_seen\": 160, \"train_examples_seen\": 31875, \"loss\": 0.09862681366503238}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "25it [00:01, 23.53it/s]\n",
      "2025-09-24 10:55:42.688 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 from 90.1206 to 90.9436\n",
      "2025-09-24 10:55:42.689 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2025-09-24 10:55:42.689 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 175: Saving model to C:\\Users\\lexan\\OneDrive\\Documents\\hackaton_lct\\models.pth.tar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 4905, \"metrics\": {\"ner_f1\": 90.9436, \"ner_token_f1\": 93.1937}, \"time_spent\": \"0:00:47\", \"epochs_done\": 1, \"batches_seen\": 160, \"train_examples_seen\": 31875, \"impatience\": 0, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 25.63it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 200, \"metrics\": {\"ner_f1\": 92.766, \"ner_token_f1\": 94.0741}, \"time_spent\": \"0:00:52\", \"epochs_done\": 1, \"batches_seen\": 180, \"train_examples_seen\": 35875, \"loss\": 0.1033324096351862}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "25it [00:00, 25.48it/s]\n",
      "2025-09-24 10:55:48.519 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 from 90.9436 to 91.6573\n",
      "2025-09-24 10:55:48.519 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2025-09-24 10:55:48.520 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 175: Saving model to C:\\Users\\lexan\\OneDrive\\Documents\\hackaton_lct\\models.pth.tar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 4905, \"metrics\": {\"ner_f1\": 91.6573, \"ner_token_f1\": 93.5552}, \"time_spent\": \"0:00:53\", \"epochs_done\": 1, \"batches_seen\": 180, \"train_examples_seen\": 35875, \"impatience\": 0, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "96it [00:28,  3.34it/s]\n",
      "1it [00:00, 23.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 200, \"metrics\": {\"ner_f1\": 91.974, \"ner_token_f1\": 92.2787}, \"time_spent\": \"0:00:58\", \"epochs_done\": 2, \"batches_seen\": 200, \"train_examples_seen\": 39750, \"loss\": 0.09151617474853993}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "25it [00:01, 24.79it/s]\n",
      "2025-09-24 10:55:54.284 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 from 91.6573 to 92.0352\n",
      "2025-09-24 10:55:54.285 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2025-09-24 10:55:54.285 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 175: Saving model to C:\\Users\\lexan\\OneDrive\\Documents\\hackaton_lct\\models.pth.tar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 4905, \"metrics\": {\"ner_f1\": 92.0352, \"ner_token_f1\": 93.9656}, \"time_spent\": \"0:00:59\", \"epochs_done\": 2, \"batches_seen\": 200, \"train_examples_seen\": 39750, \"impatience\": 0, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 26.66it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 200, \"metrics\": {\"ner_f1\": 95.8848, \"ner_token_f1\": 97.2274}, \"time_spent\": \"0:01:03\", \"epochs_done\": 2, \"batches_seen\": 220, \"train_examples_seen\": 43750, \"loss\": 0.0806550147011876}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "25it [00:00, 25.06it/s]\n",
      "2025-09-24 10:56:00.253 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 from 92.0352 to 92.2931\n",
      "2025-09-24 10:56:00.254 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2025-09-24 10:56:00.254 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 175: Saving model to C:\\Users\\lexan\\OneDrive\\Documents\\hackaton_lct\\models.pth.tar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 4905, \"metrics\": {\"ner_f1\": 92.2931, \"ner_token_f1\": 93.9673}, \"time_spent\": \"0:01:05\", \"epochs_done\": 2, \"batches_seen\": 220, \"train_examples_seen\": 43750, \"impatience\": 0, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 24.68it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 200, \"metrics\": {\"ner_f1\": 93.722, \"ner_token_f1\": 96.7864}, \"time_spent\": \"0:01:25\", \"epochs_done\": 2, \"batches_seen\": 240, \"train_examples_seen\": 47750, \"loss\": 0.07241114620119334}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "25it [00:00, 25.09it/s]\n",
      "2025-09-24 10:56:22.153 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 92.2931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 4905, \"metrics\": {\"ner_f1\": 91.5772, \"ner_token_f1\": 93.561}, \"time_spent\": \"0:01:26\", \"epochs_done\": 2, \"batches_seen\": 240, \"train_examples_seen\": 47750, \"impatience\": 1, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 26.06it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 200, \"metrics\": {\"ner_f1\": 95.3782, \"ner_token_f1\": 96.475}, \"time_spent\": \"0:01:29\", \"epochs_done\": 2, \"batches_seen\": 260, \"train_examples_seen\": 51750, \"loss\": 0.06788036208599806}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "25it [00:01, 22.57it/s]\n",
      "2025-09-24 10:56:25.689 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 from 92.2931 to 92.6674\n",
      "2025-09-24 10:56:25.689 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2025-09-24 10:56:25.690 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 175: Saving model to C:\\Users\\lexan\\OneDrive\\Documents\\hackaton_lct\\models.pth.tar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 4905, \"metrics\": {\"ner_f1\": 92.6674, \"ner_token_f1\": 94.3481}, \"time_spent\": \"0:01:30\", \"epochs_done\": 2, \"batches_seen\": 260, \"train_examples_seen\": 51750, \"impatience\": 0, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 23.06it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 200, \"metrics\": {\"ner_f1\": 96.4657, \"ner_token_f1\": 97.026}, \"time_spent\": \"0:01:35\", \"epochs_done\": 2, \"batches_seen\": 280, \"train_examples_seen\": 55750, \"loss\": 0.07008224949240685}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "25it [00:00, 25.03it/s]\n",
      "2025-09-24 10:56:31.677 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 92.6674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 4905, \"metrics\": {\"ner_f1\": 92.3077, \"ner_token_f1\": 94.1221}, \"time_spent\": \"0:01:36\", \"epochs_done\": 2, \"batches_seen\": 280, \"train_examples_seen\": 55750, \"impatience\": 1, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "96it [00:40,  2.39it/s]\n",
      "1it [00:00, 24.39it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 200, \"metrics\": {\"ner_f1\": 96.5092, \"ner_token_f1\": 96.9589}, \"time_spent\": \"0:01:38\", \"epochs_done\": 3, \"batches_seen\": 300, \"train_examples_seen\": 59625, \"loss\": 0.059921715315431355}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "25it [00:01, 24.80it/s]\n",
      "2025-09-24 10:56:35.14 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 from 92.6674 to 92.8894\n",
      "2025-09-24 10:56:35.15 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2025-09-24 10:56:35.15 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 175: Saving model to C:\\Users\\lexan\\OneDrive\\Documents\\hackaton_lct\\models.pth.tar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 4905, \"metrics\": {\"ner_f1\": 92.8894, \"ner_token_f1\": 94.5019}, \"time_spent\": \"0:01:39\", \"epochs_done\": 3, \"batches_seen\": 300, \"train_examples_seen\": 59625, \"impatience\": 0, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 26.66it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 200, \"metrics\": {\"ner_f1\": 95.7871, \"ner_token_f1\": 96.6038}, \"time_spent\": \"0:01:45\", \"epochs_done\": 3, \"batches_seen\": 320, \"train_examples_seen\": 63625, \"loss\": 0.051504948362708095}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "25it [00:01, 24.63it/s]\n",
      "2025-09-24 10:56:41.640 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 from 92.8894 to 92.9434\n",
      "2025-09-24 10:56:41.640 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2025-09-24 10:56:41.641 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 175: Saving model to C:\\Users\\lexan\\OneDrive\\Documents\\hackaton_lct\\models.pth.tar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 4905, \"metrics\": {\"ner_f1\": 92.9434, \"ner_token_f1\": 94.4872}, \"time_spent\": \"0:01:46\", \"epochs_done\": 3, \"batches_seen\": 320, \"train_examples_seen\": 63625, \"impatience\": 0, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 27.01it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 200, \"metrics\": {\"ner_f1\": 96.5957, \"ner_token_f1\": 96.9349}, \"time_spent\": \"0:01:51\", \"epochs_done\": 3, \"batches_seen\": 340, \"train_examples_seen\": 67625, \"loss\": 0.053199262171983716}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "25it [00:01, 23.90it/s]\n",
      "2025-09-24 10:56:47.694 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 92.9434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 4905, \"metrics\": {\"ner_f1\": 92.7056, \"ner_token_f1\": 94.5335}, \"time_spent\": \"0:01:52\", \"epochs_done\": 3, \"batches_seen\": 340, \"train_examples_seen\": 67625, \"impatience\": 1, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 17.69it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 200, \"metrics\": {\"ner_f1\": 97.1047, \"ner_token_f1\": 98.2857}, \"time_spent\": \"0:01:55\", \"epochs_done\": 3, \"batches_seen\": 360, \"train_examples_seen\": 71625, \"loss\": 0.056717462837696075}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "25it [00:01, 24.05it/s]\n",
      "2025-09-24 10:56:51.309 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 from 92.9434 to 93.0172\n",
      "2025-09-24 10:56:51.310 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2025-09-24 10:56:51.310 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 175: Saving model to C:\\Users\\lexan\\OneDrive\\Documents\\hackaton_lct\\models.pth.tar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 4905, \"metrics\": {\"ner_f1\": 93.0172, \"ner_token_f1\": 94.5068}, \"time_spent\": \"0:01:56\", \"epochs_done\": 3, \"batches_seen\": 360, \"train_examples_seen\": 71625, \"impatience\": 0, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 26.66it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 200, \"metrics\": {\"ner_f1\": 97.7035, \"ner_token_f1\": 98.2456}, \"time_spent\": \"0:02:01\", \"epochs_done\": 3, \"batches_seen\": 380, \"train_examples_seen\": 75625, \"loss\": 0.05809440398588776}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "25it [00:00, 25.08it/s]\n",
      "2025-09-24 10:56:57.376 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 from 93.0172 to 93.1793\n",
      "2025-09-24 10:56:57.376 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2025-09-24 10:56:57.377 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 175: Saving model to C:\\Users\\lexan\\OneDrive\\Documents\\hackaton_lct\\models.pth.tar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 4905, \"metrics\": {\"ner_f1\": 93.1793, \"ner_token_f1\": 94.7519}, \"time_spent\": \"0:02:02\", \"epochs_done\": 3, \"batches_seen\": 380, \"train_examples_seen\": 75625, \"impatience\": 0, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "96it [00:27,  3.45it/s]\n",
      "1it [00:00, 25.31it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 200, \"metrics\": {\"ner_f1\": 95.8785, \"ner_token_f1\": 96.9697}, \"time_spent\": \"0:02:06\", \"epochs_done\": 4, \"batches_seen\": 400, \"train_examples_seen\": 79500, \"loss\": 0.04766143308952451}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "25it [00:01, 22.58it/s]\n",
      "2025-09-24 10:57:03.370 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 from 93.1793 to 93.3057\n",
      "2025-09-24 10:57:03.371 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2025-09-24 10:57:03.371 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 175: Saving model to C:\\Users\\lexan\\OneDrive\\Documents\\hackaton_lct\\models.pth.tar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 4905, \"metrics\": {\"ner_f1\": 93.3057, \"ner_token_f1\": 94.9528}, \"time_spent\": \"0:02:08\", \"epochs_done\": 4, \"batches_seen\": 400, \"train_examples_seen\": 79500, \"impatience\": 0, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 22.98it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 200, \"metrics\": {\"ner_f1\": 98.2906, \"ner_token_f1\": 98.513}, \"time_spent\": \"0:02:18\", \"epochs_done\": 4, \"batches_seen\": 420, \"train_examples_seen\": 83500, \"loss\": 0.04447113210335374}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "25it [00:00, 25.21it/s]\n",
      "2025-09-24 10:57:14.845 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 93.3057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 4905, \"metrics\": {\"ner_f1\": 92.9849, \"ner_token_f1\": 94.7006}, \"time_spent\": \"0:02:19\", \"epochs_done\": 4, \"batches_seen\": 420, \"train_examples_seen\": 83500, \"impatience\": 1, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 26.32it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 200, \"metrics\": {\"ner_f1\": 95.2174, \"ner_token_f1\": 96.9582}, \"time_spent\": \"0:02:21\", \"epochs_done\": 4, \"batches_seen\": 440, \"train_examples_seen\": 87500, \"loss\": 0.03942326791584492}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "25it [00:01, 24.43it/s]\n",
      "2025-09-24 10:57:18.246 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 from 93.3057 to 93.5414\n",
      "2025-09-24 10:57:18.247 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2025-09-24 10:57:18.247 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 175: Saving model to C:\\Users\\lexan\\OneDrive\\Documents\\hackaton_lct\\models.pth.tar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 4905, \"metrics\": {\"ner_f1\": 93.5414, \"ner_token_f1\": 94.9117}, \"time_spent\": \"0:02:23\", \"epochs_done\": 4, \"batches_seen\": 440, \"train_examples_seen\": 87500, \"impatience\": 0, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 24.34it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 200, \"metrics\": {\"ner_f1\": 97.4026, \"ner_token_f1\": 98.3051}, \"time_spent\": \"0:02:32\", \"epochs_done\": 4, \"batches_seen\": 460, \"train_examples_seen\": 91500, \"loss\": 0.039522151462733746}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "25it [00:01, 24.80it/s]\n",
      "2025-09-24 10:57:28.404 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 93.5414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 4905, \"metrics\": {\"ner_f1\": 93.163, \"ner_token_f1\": 94.8255}, \"time_spent\": \"0:02:33\", \"epochs_done\": 4, \"batches_seen\": 460, \"train_examples_seen\": 91500, \"impatience\": 1, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 22.72it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 200, \"metrics\": {\"ner_f1\": 99.5851, \"ner_token_f1\": 99.635}, \"time_spent\": \"0:02:35\", \"epochs_done\": 4, \"batches_seen\": 480, \"train_examples_seen\": 95375, \"loss\": 0.04458972038701177}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "25it [00:01, 24.77it/s]\n",
      "2025-09-24 10:57:31.728 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 93.5414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 4905, \"metrics\": {\"ner_f1\": 93.3091, \"ner_token_f1\": 94.8355}, \"time_spent\": \"0:02:36\", \"epochs_done\": 4, \"batches_seen\": 480, \"train_examples_seen\": 95375, \"impatience\": 2, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "96it [00:31,  3.06it/s]\n",
      "1it [00:00, 24.00it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 200, \"metrics\": {\"ner_f1\": 96.5665, \"ner_token_f1\": 97.7072}, \"time_spent\": \"0:02:38\", \"epochs_done\": 5, \"batches_seen\": 500, \"train_examples_seen\": 99375, \"loss\": 0.03611714066937566}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "25it [00:00, 25.08it/s]\n",
      "2025-09-24 10:57:35.43 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 from 93.5414 to 93.6924\n",
      "2025-09-24 10:57:35.43 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2025-09-24 10:57:35.44 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 175: Saving model to C:\\Users\\lexan\\OneDrive\\Documents\\hackaton_lct\\models.pth.tar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 4905, \"metrics\": {\"ner_f1\": 93.6924, \"ner_token_f1\": 95.0248}, \"time_spent\": \"0:02:39\", \"epochs_done\": 5, \"batches_seen\": 500, \"train_examples_seen\": 99375, \"impatience\": 0, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 25.97it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 200, \"metrics\": {\"ner_f1\": 97.4138, \"ner_token_f1\": 97.9817}, \"time_spent\": \"0:02:44\", \"epochs_done\": 5, \"batches_seen\": 520, \"train_examples_seen\": 103375, \"loss\": 0.027850639633834363}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "25it [00:01, 22.37it/s]\n",
      "2025-09-24 10:57:41.228 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 93.6924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 4905, \"metrics\": {\"ner_f1\": 93.1185, \"ner_token_f1\": 94.6279}, \"time_spent\": \"0:02:46\", \"epochs_done\": 5, \"batches_seen\": 520, \"train_examples_seen\": 103375, \"impatience\": 1, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 23.26it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 200, \"metrics\": {\"ner_f1\": 97.6939, \"ner_token_f1\": 98.0322}, \"time_spent\": \"0:02:48\", \"epochs_done\": 5, \"batches_seen\": 540, \"train_examples_seen\": 107375, \"loss\": 0.030464535159990192}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "25it [00:01, 24.62it/s]\n",
      "2025-09-24 10:57:44.644 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 93.6924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 4905, \"metrics\": {\"ner_f1\": 93.6137, \"ner_token_f1\": 94.897}, \"time_spent\": \"0:02:49\", \"epochs_done\": 5, \"batches_seen\": 540, \"train_examples_seen\": 107375, \"impatience\": 2, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 25.64it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 200, \"metrics\": {\"ner_f1\": 99.1561, \"ner_token_f1\": 99.6212}, \"time_spent\": \"0:02:51\", \"epochs_done\": 5, \"batches_seen\": 560, \"train_examples_seen\": 111375, \"loss\": 0.03391988631337881}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "25it [00:00, 25.15it/s]\n",
      "2025-09-24 10:57:47.960 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 93.6924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 4905, \"metrics\": {\"ner_f1\": 93.4515, \"ner_token_f1\": 94.8451}, \"time_spent\": \"0:02:52\", \"epochs_done\": 5, \"batches_seen\": 560, \"train_examples_seen\": 111375, \"impatience\": 3, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "96it [00:17,  5.34it/s]\n",
      "1it [00:00, 26.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 200, \"metrics\": {\"ner_f1\": 98.1211, \"ner_token_f1\": 98.9091}, \"time_spent\": \"0:02:55\", \"epochs_done\": 6, \"batches_seen\": 580, \"train_examples_seen\": 115250, \"loss\": 0.0314412385225296}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "25it [00:01, 24.69it/s]\n",
      "2025-09-24 10:57:51.285 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 from 93.6924 to 93.7581\n",
      "2025-09-24 10:57:51.286 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2025-09-24 10:57:51.287 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 175: Saving model to C:\\Users\\lexan\\OneDrive\\Documents\\hackaton_lct\\models.pth.tar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 4905, \"metrics\": {\"ner_f1\": 93.7581, \"ner_token_f1\": 95.2068}, \"time_spent\": \"0:02:56\", \"epochs_done\": 6, \"batches_seen\": 580, \"train_examples_seen\": 115250, \"impatience\": 0, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 19.91it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 200, \"metrics\": {\"ner_f1\": 98.9293, \"ner_token_f1\": 98.7433}, \"time_spent\": \"0:03:01\", \"epochs_done\": 6, \"batches_seen\": 600, \"train_examples_seen\": 119250, \"loss\": 0.024526761518791317}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "25it [00:01, 22.15it/s]\n",
      "2025-09-24 10:57:57.559 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 93.7581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 4905, \"metrics\": {\"ner_f1\": 93.4275, \"ner_token_f1\": 94.8319}, \"time_spent\": \"0:03:02\", \"epochs_done\": 6, \"batches_seen\": 600, \"train_examples_seen\": 119250, \"impatience\": 1, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 22.71it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 200, \"metrics\": {\"ner_f1\": 97.8541, \"ner_token_f1\": 98.2079}, \"time_spent\": \"0:03:04\", \"epochs_done\": 6, \"batches_seen\": 620, \"train_examples_seen\": 123250, \"loss\": 0.0246260556159541}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "25it [00:01, 24.74it/s]\n",
      "2025-09-24 10:58:01.9 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 from 93.7581 to 93.862\n",
      "2025-09-24 10:58:01.9 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2025-09-24 10:58:01.10 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 175: Saving model to C:\\Users\\lexan\\OneDrive\\Documents\\hackaton_lct\\models.pth.tar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 4905, \"metrics\": {\"ner_f1\": 93.862, \"ner_token_f1\": 95.1697}, \"time_spent\": \"0:03:05\", \"epochs_done\": 6, \"batches_seen\": 620, \"train_examples_seen\": 123250, \"impatience\": 0, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 22.95it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 200, \"metrics\": {\"ner_f1\": 98.7124, \"ner_token_f1\": 98.9011}, \"time_spent\": \"0:03:10\", \"epochs_done\": 6, \"batches_seen\": 640, \"train_examples_seen\": 127250, \"loss\": 0.025527043780311943}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "25it [00:01, 24.28it/s]\n",
      "2025-09-24 10:58:07.44 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 93.862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 4905, \"metrics\": {\"ner_f1\": 93.7565, \"ner_token_f1\": 95.0912}, \"time_spent\": \"0:03:11\", \"epochs_done\": 6, \"batches_seen\": 640, \"train_examples_seen\": 127250, \"impatience\": 1, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 23.52it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 200, \"metrics\": {\"ner_f1\": 99.5781, \"ner_token_f1\": 99.6337}, \"time_spent\": \"0:03:14\", \"epochs_done\": 6, \"batches_seen\": 660, \"train_examples_seen\": 131250, \"loss\": 0.024122279649600387}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "25it [00:01, 24.68it/s]\n",
      "2025-09-24 10:58:10.443 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 93.862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 4905, \"metrics\": {\"ner_f1\": 93.5904, \"ner_token_f1\": 94.887}, \"time_spent\": \"0:03:15\", \"epochs_done\": 6, \"batches_seen\": 660, \"train_examples_seen\": 131250, \"impatience\": 2, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "96it [00:22,  4.36it/s]\n",
      "1it [00:00, 21.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 200, \"metrics\": {\"ner_f1\": 98.2833, \"ner_token_f1\": 98.6965}, \"time_spent\": \"0:03:17\", \"epochs_done\": 7, \"batches_seen\": 680, \"train_examples_seen\": 135125, \"loss\": 0.024834553943946958}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "25it [00:01, 22.82it/s]\n",
      "2025-09-24 10:58:13.879 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 93.862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 4905, \"metrics\": {\"ner_f1\": 93.6413, \"ner_token_f1\": 94.9686}, \"time_spent\": \"0:03:18\", \"epochs_done\": 7, \"batches_seen\": 680, \"train_examples_seen\": 135125, \"impatience\": 3, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 24.39it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 200, \"metrics\": {\"ner_f1\": 98.7124, \"ner_token_f1\": 98.9247}, \"time_spent\": \"0:03:21\", \"epochs_done\": 7, \"batches_seen\": 700, \"train_examples_seen\": 139125, \"loss\": 0.020714813726954162}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "25it [00:01, 24.89it/s]\n",
      "2025-09-24 10:58:17.261 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 93.862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 4905, \"metrics\": {\"ner_f1\": 93.6556, \"ner_token_f1\": 95.0568}, \"time_spent\": \"0:03:22\", \"epochs_done\": 7, \"batches_seen\": 700, \"train_examples_seen\": 139125, \"impatience\": 4, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 23.26it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 200, \"metrics\": {\"ner_f1\": 99.3521, \"ner_token_f1\": 99.6255}, \"time_spent\": \"0:03:24\", \"epochs_done\": 7, \"batches_seen\": 720, \"train_examples_seen\": 143125, \"loss\": 0.018143083667382598}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "25it [00:01, 23.37it/s]\n",
      "2025-09-24 10:58:20.751 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 93.862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 4905, \"metrics\": {\"ner_f1\": 93.3577, \"ner_token_f1\": 94.9064}, \"time_spent\": \"0:03:25\", \"epochs_done\": 7, \"batches_seen\": 720, \"train_examples_seen\": 143125, \"impatience\": 5, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 23.53it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 200, \"metrics\": {\"ner_f1\": 99.3658, \"ner_token_f1\": 99.8138}, \"time_spent\": \"0:03:27\", \"epochs_done\": 7, \"batches_seen\": 740, \"train_examples_seen\": 147125, \"loss\": 0.019030520971864463}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "25it [00:01, 24.12it/s]\n",
      "2025-09-24 10:58:24.287 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 93.862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 4905, \"metrics\": {\"ner_f1\": 93.5694, \"ner_token_f1\": 94.9951}, \"time_spent\": \"0:03:29\", \"epochs_done\": 7, \"batches_seen\": 740, \"train_examples_seen\": 147125, \"impatience\": 6, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 27.79it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 200, \"metrics\": {\"ner_f1\": 99.7947, \"ner_token_f1\": 99.8145}, \"time_spent\": \"0:03:31\", \"epochs_done\": 7, \"batches_seen\": 760, \"train_examples_seen\": 151125, \"loss\": 0.021747771883383393}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "25it [00:00, 25.30it/s]\n",
      "2025-09-24 10:58:27.607 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 from 93.862 to 93.8786\n",
      "2025-09-24 10:58:27.608 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2025-09-24 10:58:27.608 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 175: Saving model to C:\\Users\\lexan\\OneDrive\\Documents\\hackaton_lct\\models.pth.tar.\n",
      "87it [00:29,  2.91it/s]\n",
      "2025-09-24 10:58:41.662 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 336: Stopped training\n",
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "25it [00:00, 25.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 4905, \"metrics\": {\"ner_f1\": 93.8786, \"ner_token_f1\": 95.1848}, \"time_spent\": \"0:00:02\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17it [00:00, 27.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"test\": {\"eval_examples_count\": 3271, \"metrics\": {\"ner_f1\": 93.7915, \"ner_token_f1\": 95.0437}, \"time_spent\": \"0:00:01\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ner_model = train_model(model_config, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c25a8b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset_reader': {'class_name': 'conll2003_reader',\n",
       "  'data_path': '../datasets/conll/',\n",
       "  'dataset_name': 'collection3',\n",
       "  'provide_pos': False,\n",
       "  'provide_chunk': False,\n",
       "  'iobes': True},\n",
       " 'dataset_iterator': {'class_name': 'data_learning_iterator'},\n",
       " 'chainer': {'in': ['x'],\n",
       "  'in_y': ['y'],\n",
       "  'pipe': [{'class_name': 'torch_transformers_ner_preprocessor',\n",
       "    'vocab_file': 'DeepPavlov/rubert-base-cased',\n",
       "    'do_lower_case': False,\n",
       "    'max_seq_length': 512,\n",
       "    'max_subword_length': 15,\n",
       "    'token_masking_prob': 0.0,\n",
       "    'in': ['x'],\n",
       "    'out': ['x_tokens',\n",
       "     'x_subword_tokens',\n",
       "     'x_subword_tok_ids',\n",
       "     'startofword_markers',\n",
       "     'attention_mask',\n",
       "     'tokens_offsets']},\n",
       "   {'id': 'tag_vocab',\n",
       "    'class_name': 'simple_vocab',\n",
       "    'unk_token': ['O'],\n",
       "    'pad_with_zeros': True,\n",
       "    'save_path': '../models/tag.dict',\n",
       "    'load_path': '../models/tag.dict',\n",
       "    'fit_on': ['y'],\n",
       "    'in': ['y'],\n",
       "    'out': ['y_ind']},\n",
       "   {'class_name': 'torch_transformers_sequence_tagger',\n",
       "    'n_tags': '#tag_vocab.len',\n",
       "    'pretrained_bert': 'DeepPavlov/rubert-base-cased',\n",
       "    'attention_probs_keep_prob': 0.5,\n",
       "    'encoder_layer_ids': [-1],\n",
       "    'optimizer': 'AdamW',\n",
       "    'optimizer_parameters': {'lr': 2e-05,\n",
       "     'weight_decay': 1e-06,\n",
       "     'betas': [0.9, 0.999],\n",
       "     'eps': 1e-06},\n",
       "    'clip_norm': 1.0,\n",
       "    'min_learning_rate': 1e-07,\n",
       "    'learning_rate_drop_patience': 30,\n",
       "    'learning_rate_drop_div': 1.5,\n",
       "    'load_before_drop': True,\n",
       "    'save_path': '../models',\n",
       "    'load_path': '../models',\n",
       "    'in': ['x_subword_tok_ids', 'attention_mask', 'startofword_markers'],\n",
       "    'in_y': ['y_ind'],\n",
       "    'out': ['y_pred_ind', 'probas']},\n",
       "   {'ref': 'tag_vocab', 'in': ['y_pred_ind'], 'out': ['y_pred']}],\n",
       "  'out': ['x_tokens', 'y_pred']},\n",
       " 'train': {'epochs': 30,\n",
       "  'batch_size': 14,\n",
       "  'metrics': [{'name': 'ner_f1', 'inputs': ['y', 'y_pred']},\n",
       "   {'name': 'ner_token_f1', 'inputs': ['y', 'y_pred']}],\n",
       "  'validation_patience': 100,\n",
       "  'val_every_n_batches': 20,\n",
       "  'log_every_n_batches': 20,\n",
       "  'show_examples': False,\n",
       "  'pytest_max_batches': 2,\n",
       "  'pytest_batch_size': 8,\n",
       "  'evaluation_targets': ['valid', 'test'],\n",
       "  'class_name': 'torch_trainer'},\n",
       " 'metadata': {'variables': {'ROOT_PATH': '~/.deeppavlov',\n",
       "   'DOWNLOADS_PATH': '~/.deeppavlov/downloads',\n",
       "   'MODELS_PATH': '~/.deeppavlov/models',\n",
       "   'TRANSFORMER': 'DeepPavlov/rubert-base-cased',\n",
       "   'MODEL_PATH': '../models'},\n",
       "  'requirements': ['c:\\\\Users\\\\lexan\\\\miniconda3\\\\envs\\\\dp310\\\\lib\\\\site-packages\\\\deeppavlov/requirements/transformers.txt',\n",
       "   'c:\\\\Users\\\\lexan\\\\miniconda3\\\\envs\\\\dp310\\\\lib\\\\site-packages\\\\deeppavlov/requirements/pytorch.txt',\n",
       "   'c:\\\\Users\\\\lexan\\\\miniconda3\\\\envs\\\\dp310\\\\lib\\\\site-packages\\\\deeppavlov/requirements/torchcrf.txt',\n",
       "   'c:\\\\Users\\\\lexan\\\\miniconda3\\\\envs\\\\dp310\\\\lib\\\\site-packages\\\\deeppavlov/requirements/sentencepiece.txt',\n",
       "   'c:\\\\Users\\\\lexan\\\\miniconda3\\\\envs\\\\dp310\\\\lib\\\\site-packages\\\\deeppavlov/requirements/protobuf.txt']}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e399f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca8fc0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lexan\\miniconda3\\envs\\dp310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\lexan\\miniconda3\\envs\\dp310\\lib\\site-packages\\huggingface_hub\\file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from deeppavlov import build_model\n",
    "\n",
    "ner_model = build_model(model_config, download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e346a202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['artfruit', 'нектари']], [['S-BRAND', 'S-TYPE']]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_model(['artfruit нектари'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4d8fee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dp310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
