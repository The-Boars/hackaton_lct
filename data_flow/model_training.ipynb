{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57024b6b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdeeppavlov\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m build_model\n\u001b[1;32m----> 3\u001b[0m ner_model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mner_collection3_bert\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstall\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lexan\\miniconda3\\envs\\dp310\\lib\\site-packages\\deeppavlov\\core\\commands\\infer.py:37\u001b[0m, in \u001b[0;36mbuild_model\u001b[1;34m(config, mode, load_trained, install, download)\u001b[0m\n\u001b[0;32m     34\u001b[0m config \u001b[38;5;241m=\u001b[39m parse_config(config)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m install:\n\u001b[1;32m---> 37\u001b[0m     \u001b[43minstall_from_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m download:\n\u001b[0;32m     39\u001b[0m     deep_download(config)\n",
      "File \u001b[1;32mc:\\Users\\lexan\\miniconda3\\envs\\dp310\\lib\\site-packages\\deeppavlov\\utils\\pip_wrapper\\pip_wrapper.py:71\u001b[0m, in \u001b[0;36minstall_from_config\u001b[1;34m(config)\u001b[0m\n\u001b[0;32m     68\u001b[0m                 requirements\u001b[38;5;241m.\u001b[39mappend(line)\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m requirements:\n\u001b[1;32m---> 71\u001b[0m     \u001b[43minstall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lexan\\miniconda3\\envs\\dp310\\lib\\site-packages\\deeppavlov\\utils\\pip_wrapper\\pip_wrapper.py:36\u001b[0m, in \u001b[0;36minstall\u001b[1;34m(*packages)\u001b[0m\n\u001b[0;32m     34\u001b[0m     log\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfound tensorflow-gpu installed, so upgrading it instead of tensorflow\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     35\u001b[0m     packages \u001b[38;5;241m=\u001b[39m [_tf_re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensorflow-gpu\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m, package) \u001b[38;5;28;01mfor\u001b[39;00m package \u001b[38;5;129;01min\u001b[39;00m packages]\n\u001b[1;32m---> 36\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m-m\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpip\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minstall\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m                                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43ms\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpackages\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m                               \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menviron\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\lexan\\miniconda3\\envs\\dp310\\lib\\subprocess.py:364\u001b[0m, in \u001b[0;36mcheck_call\u001b[1;34m(*popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcheck_call\u001b[39m(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    355\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run command with arguments.  Wait for command to complete.  If\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;124;03m    the exit code was zero then return, otherwise raise\u001b[39;00m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;124;03m    CalledProcessError.  The CalledProcessError object will have the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;124;03m    check_call([\"ls\", \"-l\"])\u001b[39;00m\n\u001b[0;32m    363\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 364\u001b[0m     retcode \u001b[38;5;241m=\u001b[39m call(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m retcode:\n\u001b[0;32m    366\u001b[0m         cmd \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\lexan\\miniconda3\\envs\\dp310\\lib\\subprocess.py:347\u001b[0m, in \u001b[0;36mcall\u001b[1;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m p:\n\u001b[0;32m    346\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 347\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m:  \u001b[38;5;66;03m# Including KeyboardInterrupt, wait handled that.\u001b[39;00m\n\u001b[0;32m    349\u001b[0m         p\u001b[38;5;241m.\u001b[39mkill()\n",
      "File \u001b[1;32mc:\\Users\\lexan\\miniconda3\\envs\\dp310\\lib\\subprocess.py:1209\u001b[0m, in \u001b[0;36mPopen.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1207\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m _time() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[0;32m   1208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1209\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1210\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1211\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[0;32m   1212\u001b[0m     \u001b[38;5;66;03m# The first keyboard interrupt waits briefly for the child to\u001b[39;00m\n\u001b[0;32m   1213\u001b[0m     \u001b[38;5;66;03m# exit under the common assumption that it also received the ^C\u001b[39;00m\n\u001b[0;32m   1214\u001b[0m     \u001b[38;5;66;03m# generated SIGINT and will exit rapidly.\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\lexan\\miniconda3\\envs\\dp310\\lib\\subprocess.py:1506\u001b[0m, in \u001b[0;36mPopen._wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1503\u001b[0m     timeout_millis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(timeout \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m)\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1505\u001b[0m     \u001b[38;5;66;03m# API note: Returns immediately if timeout_millis == 0.\u001b[39;00m\n\u001b[1;32m-> 1506\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWaitForSingleObject\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1507\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mtimeout_millis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1508\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;241m==\u001b[39m _winapi\u001b[38;5;241m.\u001b[39mWAIT_TIMEOUT:\n\u001b[0;32m   1509\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m TimeoutExpired(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, timeout)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from deeppavlov import build_model\n",
    "\n",
    "ner_model = build_model('ner_collection3_bert', download=True, install=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cebaef7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~/.deeppavlov/downloads/collection3/\n"
     ]
    }
   ],
   "source": [
    "from deeppavlov import train_model, build_model \n",
    "from deeppavlov.core.commands.utils import parse_config\n",
    "\n",
    "PROJECT_DIR = '..'\n",
    "MODEL_NAME = 'model'\n",
    "\n",
    "model_config = parse_config('ner_collection3_bert')\n",
    "\n",
    "# dataset that the model was trained on\n",
    "print(model_config['dataset_reader']['data_path'])\n",
    "\n",
    "model_config['dataset_reader']['data_path'] = PROJECT_DIR + '/datasets/conll/'\n",
    "\n",
    "del model_config['metadata']['download']\n",
    "\n",
    "\n",
    "model_config['dataset_reader']['iobes'] = False\n",
    "model_config['metadata']['variables']['MODEL_PATH'] = PROJECT_DIR + '/models/' + MODEL_NAME\n",
    "\n",
    "model_config['chainer']['pipe'][1]['save_path'] = PROJECT_DIR + '/models/tag.dict'\n",
    "model_config['chainer']['pipe'][1]['load_path'] = PROJECT_DIR + '/models/tag.dict'\n",
    "\n",
    "model_config['chainer']['pipe'][2]['save_path'] = PROJECT_DIR + '/models/' + MODEL_NAME\n",
    "model_config['chainer']['pipe'][2]['load_path'] = PROJECT_DIR + '/models/' + MODEL_NAME\n",
    "\n",
    "\n",
    "model_config['train']['batch_size'] = 600\n",
    "\n",
    "model_config['train']['log_every_n_batches'] = 10\n",
    "model_config['train']['val_every_n_batches'] = 10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f1a155a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset_reader': {'class_name': 'conll2003_reader',\n",
       "  'data_path': '../datasets/conll/',\n",
       "  'dataset_name': 'collection3',\n",
       "  'provide_pos': False,\n",
       "  'provide_chunk': False,\n",
       "  'iobes': True},\n",
       " 'dataset_iterator': {'class_name': 'data_learning_iterator'},\n",
       " 'chainer': {'in': ['x'],\n",
       "  'in_y': ['y'],\n",
       "  'pipe': [{'class_name': 'torch_transformers_ner_preprocessor',\n",
       "    'vocab_file': 'DeepPavlov/rubert-base-cased',\n",
       "    'do_lower_case': False,\n",
       "    'max_seq_length': 512,\n",
       "    'max_subword_length': 15,\n",
       "    'token_masking_prob': 0.0,\n",
       "    'in': ['x'],\n",
       "    'out': ['x_tokens',\n",
       "     'x_subword_tokens',\n",
       "     'x_subword_tok_ids',\n",
       "     'startofword_markers',\n",
       "     'attention_mask',\n",
       "     'tokens_offsets']},\n",
       "   {'id': 'tag_vocab',\n",
       "    'class_name': 'simple_vocab',\n",
       "    'unk_token': ['O'],\n",
       "    'pad_with_zeros': True,\n",
       "    'save_path': '../models/tag.dict',\n",
       "    'load_path': '../models/tag.dict',\n",
       "    'fit_on': ['y'],\n",
       "    'in': ['y'],\n",
       "    'out': ['y_ind']},\n",
       "   {'class_name': 'torch_transformers_sequence_tagger',\n",
       "    'n_tags': '#tag_vocab.len',\n",
       "    'pretrained_bert': 'DeepPavlov/rubert-base-cased',\n",
       "    'attention_probs_keep_prob': 0.5,\n",
       "    'encoder_layer_ids': [-1],\n",
       "    'optimizer': 'AdamW',\n",
       "    'optimizer_parameters': {'lr': 2e-05,\n",
       "     'weight_decay': 1e-06,\n",
       "     'betas': [0.9, 0.999],\n",
       "     'eps': 1e-06},\n",
       "    'clip_norm': 1.0,\n",
       "    'min_learning_rate': 1e-07,\n",
       "    'learning_rate_drop_patience': 30,\n",
       "    'learning_rate_drop_div': 1.5,\n",
       "    'load_before_drop': True,\n",
       "    'save_path': '../models/model',\n",
       "    'load_path': '../models/model',\n",
       "    'in': ['x_subword_tok_ids', 'attention_mask', 'startofword_markers'],\n",
       "    'in_y': ['y_ind'],\n",
       "    'out': ['y_pred_ind', 'probas']},\n",
       "   {'ref': 'tag_vocab', 'in': ['y_pred_ind'], 'out': ['y_pred']}],\n",
       "  'out': ['x_tokens', 'y_pred']},\n",
       " 'train': {'epochs': 30,\n",
       "  'batch_size': 400,\n",
       "  'metrics': [{'name': 'ner_f1', 'inputs': ['y', 'y_pred']},\n",
       "   {'name': 'ner_token_f1', 'inputs': ['y', 'y_pred']}],\n",
       "  'validation_patience': 100,\n",
       "  'val_every_n_batches': 10,\n",
       "  'log_every_n_batches': 10,\n",
       "  'show_examples': False,\n",
       "  'pytest_max_batches': 2,\n",
       "  'pytest_batch_size': 8,\n",
       "  'evaluation_targets': ['valid', 'test'],\n",
       "  'class_name': 'torch_trainer'},\n",
       " 'metadata': {'variables': {'ROOT_PATH': '~/.deeppavlov',\n",
       "   'DOWNLOADS_PATH': '~/.deeppavlov/downloads',\n",
       "   'MODELS_PATH': '~/.deeppavlov/models',\n",
       "   'TRANSFORMER': 'DeepPavlov/rubert-base-cased',\n",
       "   'MODEL_PATH': '../models/model'},\n",
       "  'requirements': ['c:\\\\Users\\\\lexan\\\\miniconda3\\\\envs\\\\dp310\\\\lib\\\\site-packages\\\\deeppavlov/requirements/torchcrf.txt',\n",
       "   'c:\\\\Users\\\\lexan\\\\miniconda3\\\\envs\\\\dp310\\\\lib\\\\site-packages\\\\deeppavlov/requirements/protobuf.txt',\n",
       "   'c:\\\\Users\\\\lexan\\\\miniconda3\\\\envs\\\\dp310\\\\lib\\\\site-packages\\\\deeppavlov/requirements/sentencepiece.txt',\n",
       "   'c:\\\\Users\\\\lexan\\\\miniconda3\\\\envs\\\\dp310\\\\lib\\\\site-packages\\\\deeppavlov/requirements/pytorch.txt',\n",
       "   'c:\\\\Users\\\\lexan\\\\miniconda3\\\\envs\\\\dp310\\\\lib\\\\site-packages\\\\deeppavlov/requirements/transformers.txt']}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecd27e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-28 13:42:27.32 WARNING in 'deeppavlov.core.trainers.fit_trainer'['fit_trainer'] at line 66: TorchTrainer got additional init parameters ['pytest_max_batches', 'pytest_batch_size'] that will be ignored:\n",
      "c:\\Users\\lexan\\miniconda3\\envs\\dp310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\lexan\\miniconda3\\envs\\dp310\\lib\\site-packages\\huggingface_hub\\file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "2025-09-28 13:42:31.689 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 104: [saving vocabulary to C:\\Users\\lexan\\OneDrive\\Documents\\hackaton_lct\\models\\tag.dict]\n",
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2025-09-28 13:42:33.768 WARNING in 'deeppavlov.core.models.torch_model'['torch_model'] at line 151: Init from scratch. Load path C:\\Users\\lexan\\OneDrive\\Documents\\hackaton_lct\\models\\model.pth.tar does not exist.\n",
      "15it [00:03,  4.79it/s]\n",
      "2025-09-28 13:42:37.14 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 198: Initial best ner_f1 of 8.1622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 8721, \"metrics\": {\"ner_f1\": 8.1622, \"ner_token_f1\": 17.4606}, \"time_spent\": \"0:00:04\", \"epochs_done\": 0, \"batches_seen\": 0, \"train_examples_seen\": 0, \"impatience\": 0, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 600, \"metrics\": {\"ner_f1\": 39.9001, \"ner_token_f1\": 44.2829}, \"time_spent\": \"0:00:08\", \"epochs_done\": 0, \"batches_seen\": 10, \"train_examples_seen\": 6000, \"loss\": 1.2645913898944854}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "15it [00:01,  7.52it/s]\n",
      "2025-09-28 13:42:43.453 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 from 8.1622 to 55.9361\n",
      "2025-09-28 13:42:43.454 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2025-09-28 13:42:43.455 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 175: Saving model to C:\\Users\\lexan\\OneDrive\\Documents\\hackaton_lct\\models\\model.pth.tar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 8721, \"metrics\": {\"ner_f1\": 55.9361, \"ner_token_f1\": 77.5977}, \"time_spent\": \"0:00:10\", \"epochs_done\": 0, \"batches_seen\": 10, \"train_examples_seen\": 6000, \"impatience\": 0, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  2.51it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 600, \"metrics\": {\"ner_f1\": 58.8276, \"ner_token_f1\": 78.1945}, \"time_spent\": \"0:00:18\", \"epochs_done\": 0, \"batches_seen\": 20, \"train_examples_seen\": 12000, \"loss\": 0.4570236146450043}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "15it [00:02,  7.40it/s]\n",
      "2025-09-28 13:42:53.100 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 from 55.9361 to 58.7128\n",
      "2025-09-28 13:42:53.100 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2025-09-28 13:42:53.102 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 175: Saving model to C:\\Users\\lexan\\OneDrive\\Documents\\hackaton_lct\\models\\model.pth.tar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 8721, \"metrics\": {\"ner_f1\": 58.7128, \"ner_token_f1\": 79.5518}, \"time_spent\": \"0:00:20\", \"epochs_done\": 0, \"batches_seen\": 20, \"train_examples_seen\": 12000, \"impatience\": 0, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  5.52it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 600, \"metrics\": {\"ner_f1\": 71.1143, \"ner_token_f1\": 95.1355}, \"time_spent\": \"0:00:27\", \"epochs_done\": 0, \"batches_seen\": 30, \"train_examples_seen\": 18000, \"loss\": 0.23129429221153258}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "15it [00:02,  7.21it/s]\n",
      "2025-09-28 13:43:02.563 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 from 58.7128 to 59.8218\n",
      "2025-09-28 13:43:02.564 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2025-09-28 13:43:02.565 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 175: Saving model to C:\\Users\\lexan\\OneDrive\\Documents\\hackaton_lct\\models\\model.pth.tar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 8721, \"metrics\": {\"ner_f1\": 59.8218, \"ner_token_f1\": 81.3557}, \"time_spent\": \"0:00:29\", \"epochs_done\": 0, \"batches_seen\": 30, \"train_examples_seen\": 18000, \"impatience\": 0, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  5.39it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 600, \"metrics\": {\"ner_f1\": 81.3288, \"ner_token_f1\": 96.5959}, \"time_spent\": \"0:00:36\", \"epochs_done\": 0, \"batches_seen\": 40, \"train_examples_seen\": 24000, \"loss\": 0.15037428215146065}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "15it [00:01,  7.84it/s]\n",
      "2025-09-28 13:43:11.364 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 from 59.8218 to 77.2609\n",
      "2025-09-28 13:43:11.365 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2025-09-28 13:43:11.366 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 175: Saving model to C:\\Users\\lexan\\OneDrive\\Documents\\hackaton_lct\\models\\model.pth.tar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 8721, \"metrics\": {\"ner_f1\": 77.2609, \"ner_token_f1\": 87.4979}, \"time_spent\": \"0:00:38\", \"epochs_done\": 0, \"batches_seen\": 40, \"train_examples_seen\": 24000, \"impatience\": 0, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  5.51it/s]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 600, \"metrics\": {\"ner_f1\": 86.9928, \"ner_token_f1\": 96.6732}, \"time_spent\": \"0:00:45\", \"epochs_done\": 0, \"batches_seen\": 50, \"train_examples_seen\": 30000, \"loss\": 0.10114511027932167}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [00:02,  6.52it/s]\n",
      "2025-09-28 13:43:20.868 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 from 77.2609 to 81.4494\n",
      "2025-09-28 13:43:20.869 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2025-09-28 13:43:20.870 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 175: Saving model to C:\\Users\\lexan\\OneDrive\\Documents\\hackaton_lct\\models\\model.pth.tar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 8721, \"metrics\": {\"ner_f1\": 81.4494, \"ner_token_f1\": 88.5399}, \"time_spent\": \"0:00:48\", \"epochs_done\": 0, \"batches_seen\": 50, \"train_examples_seen\": 30000, \"impatience\": 0, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "58it [00:49,  1.16it/s]\n",
      "1it [00:00,  5.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 600, \"metrics\": {\"ner_f1\": 93.0847, \"ner_token_f1\": 96.918}, \"time_spent\": \"0:00:55\", \"epochs_done\": 1, \"batches_seen\": 60, \"train_examples_seen\": 35866, \"loss\": 0.07389329560101032}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "15it [00:01,  7.73it/s]\n",
      "2025-09-28 13:43:29.823 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 from 81.4494 to 85.2308\n",
      "2025-09-28 13:43:29.824 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2025-09-28 13:43:29.824 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 175: Saving model to C:\\Users\\lexan\\OneDrive\\Documents\\hackaton_lct\\models\\model.pth.tar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 8721, \"metrics\": {\"ner_f1\": 85.2308, \"ner_token_f1\": 89.6802}, \"time_spent\": \"0:00:57\", \"epochs_done\": 1, \"batches_seen\": 60, \"train_examples_seen\": 35866, \"impatience\": 0, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  5.35it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 600, \"metrics\": {\"ner_f1\": 94.9333, \"ner_token_f1\": 97.8558}, \"time_spent\": \"0:01:04\", \"epochs_done\": 1, \"batches_seen\": 70, \"train_examples_seen\": 41866, \"loss\": 0.05799860022962093}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "15it [00:02,  7.31it/s]\n",
      "2025-09-28 13:43:39.278 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 from 85.2308 to 86.0894\n",
      "2025-09-28 13:43:39.279 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2025-09-28 13:43:39.280 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 175: Saving model to C:\\Users\\lexan\\OneDrive\\Documents\\hackaton_lct\\models\\model.pth.tar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 8721, \"metrics\": {\"ner_f1\": 86.0894, \"ner_token_f1\": 90.313}, \"time_spent\": \"0:01:06\", \"epochs_done\": 1, \"batches_seen\": 70, \"train_examples_seen\": 41866, \"impatience\": 0, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  5.09it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 600, \"metrics\": {\"ner_f1\": 95.4984, \"ner_token_f1\": 97.2663}, \"time_spent\": \"0:01:20\", \"epochs_done\": 1, \"batches_seen\": 80, \"train_examples_seen\": 47866, \"loss\": 0.04924185685813427}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "15it [00:01,  7.79it/s]\n",
      "2025-09-28 13:43:55.440 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 from 86.0894 to 87.0646\n",
      "2025-09-28 13:43:55.441 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2025-09-28 13:43:55.442 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 175: Saving model to C:\\Users\\lexan\\OneDrive\\Documents\\hackaton_lct\\models\\model.pth.tar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 8721, \"metrics\": {\"ner_f1\": 87.0646, \"ner_token_f1\": 90.8165}, \"time_spent\": \"0:01:22\", \"epochs_done\": 1, \"batches_seen\": 80, \"train_examples_seen\": 47866, \"impatience\": 0, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  4.65it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 600, \"metrics\": {\"ner_f1\": 94.8816, \"ner_token_f1\": 97.5783}, \"time_spent\": \"0:01:34\", \"epochs_done\": 1, \"batches_seen\": 90, \"train_examples_seen\": 53866, \"loss\": 0.04790712296962738}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "15it [00:01,  7.72it/s]\n",
      "2025-09-28 13:44:09.728 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 from 87.0646 to 87.5012\n",
      "2025-09-28 13:44:09.729 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2025-09-28 13:44:09.730 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 175: Saving model to C:\\Users\\lexan\\OneDrive\\Documents\\hackaton_lct\\models\\model.pth.tar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 8721, \"metrics\": {\"ner_f1\": 87.5012, \"ner_token_f1\": 91.1833}, \"time_spent\": \"0:01:36\", \"epochs_done\": 1, \"batches_seen\": 90, \"train_examples_seen\": 53866, \"impatience\": 0, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  5.59it/s]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 600, \"metrics\": {\"ner_f1\": 95.9395, \"ner_token_f1\": 98.1732}, \"time_spent\": \"0:01:44\", \"epochs_done\": 1, \"batches_seen\": 100, \"train_examples_seen\": 59866, \"loss\": 0.04490296058356762}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [00:02,  7.21it/s]\n",
      "2025-09-28 13:44:19.42 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 from 87.5012 to 88.0141\n",
      "2025-09-28 13:44:19.43 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2025-09-28 13:44:19.44 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 175: Saving model to C:\\Users\\lexan\\OneDrive\\Documents\\hackaton_lct\\models\\model.pth.tar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 8721, \"metrics\": {\"ner_f1\": 88.0141, \"ner_token_f1\": 91.4241}, \"time_spent\": \"0:01:46\", \"epochs_done\": 1, \"batches_seen\": 100, \"train_examples_seen\": 59866, \"impatience\": 0, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  5.32it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 600, \"metrics\": {\"ner_f1\": 97.0818, \"ner_token_f1\": 97.6873}, \"time_spent\": \"0:01:53\", \"epochs_done\": 1, \"batches_seen\": 110, \"train_examples_seen\": 65866, \"loss\": 0.04407770521938801}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "15it [00:01,  7.89it/s]\n",
      "2025-09-28 13:44:28.143 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 from 88.0141 to 88.5572\n",
      "2025-09-28 13:44:28.145 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2025-09-28 13:44:28.146 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 175: Saving model to C:\\Users\\lexan\\OneDrive\\Documents\\hackaton_lct\\models\\model.pth.tar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 8721, \"metrics\": {\"ner_f1\": 88.5572, \"ner_token_f1\": 91.8103}, \"time_spent\": \"0:01:55\", \"epochs_done\": 1, \"batches_seen\": 110, \"train_examples_seen\": 65866, \"impatience\": 0, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "58it [01:06,  1.15s/it]\n",
      "1it [00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 600, \"metrics\": {\"ner_f1\": 95.9684, \"ner_token_f1\": 98.3266}, \"time_spent\": \"0:02:02\", \"epochs_done\": 2, \"batches_seen\": 120, \"train_examples_seen\": 71732, \"loss\": 0.038220832496881484}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [00:02,  6.86it/s]\n",
      "2025-09-28 13:44:37.725 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 88.5572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 8721, \"metrics\": {\"ner_f1\": 88.5374, \"ner_token_f1\": 91.8229}, \"time_spent\": \"0:02:04\", \"epochs_done\": 2, \"batches_seen\": 120, \"train_examples_seen\": 71732, \"impatience\": 1, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  4.81it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 600, \"metrics\": {\"ner_f1\": 97.037, \"ner_token_f1\": 97.9421}, \"time_spent\": \"0:02:09\", \"epochs_done\": 2, \"batches_seen\": 130, \"train_examples_seen\": 77732, \"loss\": 0.035304102674126626}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "15it [00:02,  7.39it/s]\n",
      "2025-09-28 13:44:44.196 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 from 88.5572 to 88.9324\n",
      "2025-09-28 13:44:44.197 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2025-09-28 13:44:44.198 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 175: Saving model to C:\\Users\\lexan\\OneDrive\\Documents\\hackaton_lct\\models\\model.pth.tar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 8721, \"metrics\": {\"ner_f1\": 88.9324, \"ner_token_f1\": 92.0229}, \"time_spent\": \"0:02:11\", \"epochs_done\": 2, \"batches_seen\": 130, \"train_examples_seen\": 77732, \"impatience\": 0, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  3.74it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 600, \"metrics\": {\"ner_f1\": 97.0974, \"ner_token_f1\": 98.15}, \"time_spent\": \"0:02:19\", \"epochs_done\": 2, \"batches_seen\": 140, \"train_examples_seen\": 83732, \"loss\": 0.032665726728737354}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "15it [00:02,  6.20it/s]\n",
      "2025-09-28 13:44:54.773 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 88.9324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 8721, \"metrics\": {\"ner_f1\": 88.582, \"ner_token_f1\": 92.0176}, \"time_spent\": \"0:02:21\", \"epochs_done\": 2, \"batches_seen\": 140, \"train_examples_seen\": 83732, \"impatience\": 1, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  4.77it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 600, \"metrics\": {\"ner_f1\": 97.8201, \"ner_token_f1\": 98.3496}, \"time_spent\": \"0:02:26\", \"epochs_done\": 2, \"batches_seen\": 150, \"train_examples_seen\": 89732, \"loss\": 0.03436853885650635}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "15it [00:02,  6.90it/s]\n",
      "2025-09-28 13:45:01.390 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 from 88.9324 to 89.3115\n",
      "2025-09-28 13:45:01.390 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2025-09-28 13:45:01.391 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 175: Saving model to C:\\Users\\lexan\\OneDrive\\Documents\\hackaton_lct\\models\\model.pth.tar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 8721, \"metrics\": {\"ner_f1\": 89.3115, \"ner_token_f1\": 92.4112}, \"time_spent\": \"0:02:28\", \"epochs_done\": 2, \"batches_seen\": 150, \"train_examples_seen\": 89732, \"impatience\": 0, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  4.58it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 600, \"metrics\": {\"ner_f1\": 97.4191, \"ner_token_f1\": 97.8133}, \"time_spent\": \"0:02:53\", \"epochs_done\": 2, \"batches_seen\": 160, \"train_examples_seen\": 95732, \"loss\": 0.032970913127064704}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "15it [00:02,  7.26it/s]\n",
      "2025-09-28 13:45:28.168 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 from 89.3115 to 89.4059\n",
      "2025-09-28 13:45:28.169 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2025-09-28 13:45:28.170 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 175: Saving model to C:\\Users\\lexan\\OneDrive\\Documents\\hackaton_lct\\models\\model.pth.tar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 8721, \"metrics\": {\"ner_f1\": 89.4059, \"ner_token_f1\": 92.4287}, \"time_spent\": \"0:02:55\", \"epochs_done\": 2, \"batches_seen\": 160, \"train_examples_seen\": 95732, \"impatience\": 0, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  4.79it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 600, \"metrics\": {\"ner_f1\": 96.3492, \"ner_token_f1\": 98.5369}, \"time_spent\": \"0:03:03\", \"epochs_done\": 2, \"batches_seen\": 170, \"train_examples_seen\": 101732, \"loss\": 0.03344575241208077}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "15it [00:02,  6.76it/s]\n",
      "2025-09-28 13:45:38.478 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 from 89.4059 to 89.6108\n",
      "2025-09-28 13:45:38.479 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2025-09-28 13:45:38.480 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 175: Saving model to C:\\Users\\lexan\\OneDrive\\Documents\\hackaton_lct\\models\\model.pth.tar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 8721, \"metrics\": {\"ner_f1\": 89.6108, \"ner_token_f1\": 92.6123}, \"time_spent\": \"0:03:05\", \"epochs_done\": 2, \"batches_seen\": 170, \"train_examples_seen\": 101732, \"impatience\": 0, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "58it [01:09,  1.20s/it]\n",
      "1it [00:00,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 600, \"metrics\": {\"ner_f1\": 98.5439, \"ner_token_f1\": 98.7065}, \"time_spent\": \"0:03:13\", \"epochs_done\": 3, \"batches_seen\": 180, \"train_examples_seen\": 107598, \"loss\": 0.031016727536916734}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "15it [00:01,  7.62it/s]\n",
      "2025-09-28 13:45:47.939 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 from 89.6108 to 89.9543\n",
      "2025-09-28 13:45:47.940 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2025-09-28 13:45:47.941 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 175: Saving model to C:\\Users\\lexan\\OneDrive\\Documents\\hackaton_lct\\models\\model.pth.tar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 8721, \"metrics\": {\"ner_f1\": 89.9543, \"ner_token_f1\": 92.6781}, \"time_spent\": \"0:03:15\", \"epochs_done\": 3, \"batches_seen\": 180, \"train_examples_seen\": 107598, \"impatience\": 0, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  4.37it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 600, \"metrics\": {\"ner_f1\": 98.5994, \"ner_token_f1\": 98.887}, \"time_spent\": \"0:03:23\", \"epochs_done\": 3, \"batches_seen\": 190, \"train_examples_seen\": 113598, \"loss\": 0.029238594137132166}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "15it [00:02,  6.19it/s]\n",
      "2025-09-28 13:45:58.414 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 89.9543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 8721, \"metrics\": {\"ner_f1\": 89.4995, \"ner_token_f1\": 92.4354}, \"time_spent\": \"0:03:25\", \"epochs_done\": 3, \"batches_seen\": 190, \"train_examples_seen\": 113598, \"impatience\": 1, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  5.03it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 600, \"metrics\": {\"ner_f1\": 98.192, \"ner_token_f1\": 98.7436}, \"time_spent\": \"0:03:30\", \"epochs_done\": 3, \"batches_seen\": 200, \"train_examples_seen\": 119598, \"loss\": 0.02698301859200001}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "15it [00:02,  6.39it/s]\n",
      "2025-09-28 13:46:05.381 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 89.9543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 8721, \"metrics\": {\"ner_f1\": 89.4218, \"ner_token_f1\": 92.394}, \"time_spent\": \"0:03:32\", \"epochs_done\": 3, \"batches_seen\": 200, \"train_examples_seen\": 119598, \"impatience\": 2, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  4.57it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 600, \"metrics\": {\"ner_f1\": 99.1324, \"ner_token_f1\": 99.2889}, \"time_spent\": \"0:03:36\", \"epochs_done\": 3, \"batches_seen\": 210, \"train_examples_seen\": 125598, \"loss\": 0.028005332313477994}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "15it [00:02,  6.98it/s]\n",
      "2025-09-28 13:46:11.940 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 89.9543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 8721, \"metrics\": {\"ner_f1\": 88.9346, \"ner_token_f1\": 91.9746}, \"time_spent\": \"0:03:39\", \"epochs_done\": 3, \"batches_seen\": 210, \"train_examples_seen\": 125598, \"impatience\": 3, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  5.28it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 600, \"metrics\": {\"ner_f1\": 98.143, \"ner_token_f1\": 98.5459}, \"time_spent\": \"0:03:43\", \"epochs_done\": 3, \"batches_seen\": 220, \"train_examples_seen\": 131598, \"loss\": 0.028028115443885327}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "15it [00:02,  7.17it/s]\n",
      "2025-09-28 13:46:18.355 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 89.9543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 8721, \"metrics\": {\"ner_f1\": 89.355, \"ner_token_f1\": 92.3479}, \"time_spent\": \"0:03:45\", \"epochs_done\": 3, \"batches_seen\": 220, \"train_examples_seen\": 131598, \"impatience\": 4, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  4.47it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 600, \"metrics\": {\"ner_f1\": 98.7471, \"ner_token_f1\": 99.3622}, \"time_spent\": \"0:03:49\", \"epochs_done\": 3, \"batches_seen\": 230, \"train_examples_seen\": 137598, \"loss\": 0.02596351969987154}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "15it [00:01,  7.82it/s]\n",
      "2025-09-28 13:46:24.307 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 from 89.9543 to 90.082\n",
      "2025-09-28 13:46:24.308 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2025-09-28 13:46:24.309 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 175: Saving model to C:\\Users\\lexan\\OneDrive\\Documents\\hackaton_lct\\models\\model.pth.tar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 8721, \"metrics\": {\"ner_f1\": 90.082, \"ner_token_f1\": 92.8107}, \"time_spent\": \"0:03:51\", \"epochs_done\": 3, \"batches_seen\": 230, \"train_examples_seen\": 137598, \"impatience\": 0, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "58it [00:45,  1.28it/s]\n",
      "1it [00:00,  4.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 600, \"metrics\": {\"ner_f1\": 98.7094, \"ner_token_f1\": 99.0698}, \"time_spent\": \"0:03:59\", \"epochs_done\": 4, \"batches_seen\": 240, \"train_examples_seen\": 143464, \"loss\": 0.024847385101020338}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "15it [00:02,  6.60it/s]\n",
      "2025-09-28 13:46:34.270 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 90.082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 8721, \"metrics\": {\"ner_f1\": 89.9543, \"ner_token_f1\": 92.8268}, \"time_spent\": \"0:04:01\", \"epochs_done\": 4, \"batches_seen\": 240, \"train_examples_seen\": 143464, \"impatience\": 1, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  4.64it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 600, \"metrics\": {\"ner_f1\": 98.5851, \"ner_token_f1\": 99.075}, \"time_spent\": \"0:04:05\", \"epochs_done\": 4, \"batches_seen\": 250, \"train_examples_seen\": 149464, \"loss\": 0.024321642704308033}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "15it [00:02,  7.48it/s]\n",
      "2025-09-28 13:46:40.527 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 90.082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 8721, \"metrics\": {\"ner_f1\": 89.7239, \"ner_token_f1\": 92.7516}, \"time_spent\": \"0:04:07\", \"epochs_done\": 4, \"batches_seen\": 250, \"train_examples_seen\": 149464, \"impatience\": 2, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  4.88it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 600, \"metrics\": {\"ner_f1\": 98.2578, \"ner_token_f1\": 99.3263}, \"time_spent\": \"0:04:11\", \"epochs_done\": 4, \"batches_seen\": 260, \"train_examples_seen\": 155464, \"loss\": 0.02395454403012991}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "15it [00:02,  6.65it/s]\n",
      "2025-09-28 13:46:47.80 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 90.082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 8721, \"metrics\": {\"ner_f1\": 89.8843, \"ner_token_f1\": 92.7741}, \"time_spent\": \"0:04:14\", \"epochs_done\": 4, \"batches_seen\": 260, \"train_examples_seen\": 155464, \"impatience\": 3, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  3.75it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 600, \"metrics\": {\"ner_f1\": 98.7565, \"ner_token_f1\": 99.115}, \"time_spent\": \"0:04:18\", \"epochs_done\": 4, \"batches_seen\": 270, \"train_examples_seen\": 161464, \"loss\": 0.021914400905370713}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "15it [00:02,  7.15it/s]\n",
      "2025-09-28 13:46:53.721 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 90.082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 8721, \"metrics\": {\"ner_f1\": 89.9706, \"ner_token_f1\": 92.6931}, \"time_spent\": \"0:04:20\", \"epochs_done\": 4, \"batches_seen\": 270, \"train_examples_seen\": 161464, \"impatience\": 4, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  4.24it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 600, \"metrics\": {\"ner_f1\": 98.8524, \"ner_token_f1\": 99.1914}, \"time_spent\": \"0:04:25\", \"epochs_done\": 4, \"batches_seen\": 280, \"train_examples_seen\": 167464, \"loss\": 0.023638037405908106}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "15it [00:01,  7.51it/s]\n",
      "2025-09-28 13:47:00.296 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 90.082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 8721, \"metrics\": {\"ner_f1\": 89.2841, \"ner_token_f1\": 92.1712}, \"time_spent\": \"0:04:27\", \"epochs_done\": 4, \"batches_seen\": 280, \"train_examples_seen\": 167464, \"impatience\": 5, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  4.51it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 600, \"metrics\": {\"ner_f1\": 99.2138, \"ner_token_f1\": 99.3053}, \"time_spent\": \"0:04:32\", \"epochs_done\": 4, \"batches_seen\": 290, \"train_examples_seen\": 173330, \"loss\": 0.022565265651792288}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "15it [00:02,  6.98it/s]\n",
      "2025-09-28 13:47:07.46 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 90.082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 8721, \"metrics\": {\"ner_f1\": 89.5125, \"ner_token_f1\": 92.2053}, \"time_spent\": \"0:04:34\", \"epochs_done\": 4, \"batches_seen\": 290, \"train_examples_seen\": 173330, \"impatience\": 6, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "58it [00:38,  1.51it/s]\n",
      "1it [00:00,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 600, \"metrics\": {\"ner_f1\": 98.7204, \"ner_token_f1\": 99.115}, \"time_spent\": \"0:04:38\", \"epochs_done\": 5, \"batches_seen\": 300, \"train_examples_seen\": 179330, \"loss\": 0.02087632827460766}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "15it [00:02,  7.44it/s]\n",
      "2025-09-28 13:47:13.483 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 90.082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 8721, \"metrics\": {\"ner_f1\": 89.1899, \"ner_token_f1\": 92.0403}, \"time_spent\": \"0:04:40\", \"epochs_done\": 5, \"batches_seen\": 300, \"train_examples_seen\": 179330, \"impatience\": 7, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  4.75it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 600, \"metrics\": {\"ner_f1\": 98.978, \"ner_token_f1\": 99.1402}, \"time_spent\": \"0:04:44\", \"epochs_done\": 5, \"batches_seen\": 310, \"train_examples_seen\": 185330, \"loss\": 0.019784708879888056}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "15it [00:02,  6.39it/s]\n",
      "2025-09-28 13:47:20.211 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 90.082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 8721, \"metrics\": {\"ner_f1\": 90.0201, \"ner_token_f1\": 92.7856}, \"time_spent\": \"0:04:47\", \"epochs_done\": 5, \"batches_seen\": 310, \"train_examples_seen\": 185330, \"impatience\": 8, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  3.83it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 600, \"metrics\": {\"ner_f1\": 98.8469, \"ner_token_f1\": 99.1653}, \"time_spent\": \"0:04:52\", \"epochs_done\": 5, \"batches_seen\": 320, \"train_examples_seen\": 191330, \"loss\": 0.020486746542155744}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "15it [00:02,  6.93it/s]\n",
      "2025-09-28 13:47:27.211 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 from 90.082 to 90.4282\n",
      "2025-09-28 13:47:27.212 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2025-09-28 13:47:27.213 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 175: Saving model to C:\\Users\\lexan\\OneDrive\\Documents\\hackaton_lct\\models\\model.pth.tar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 8721, \"metrics\": {\"ner_f1\": 90.4282, \"ner_token_f1\": 93.052}, \"time_spent\": \"0:04:54\", \"epochs_done\": 5, \"batches_seen\": 320, \"train_examples_seen\": 191330, \"impatience\": 0, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  4.55it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 600, \"metrics\": {\"ner_f1\": 98.8381, \"ner_token_f1\": 99.3494}, \"time_spent\": \"0:05:02\", \"epochs_done\": 5, \"batches_seen\": 330, \"train_examples_seen\": 197330, \"loss\": 0.018530879449099303}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "15it [00:02,  6.88it/s]\n",
      "2025-09-28 13:47:37.250 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 90.4282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 8721, \"metrics\": {\"ner_f1\": 90.3357, \"ner_token_f1\": 93.0137}, \"time_spent\": \"0:05:04\", \"epochs_done\": 5, \"batches_seen\": 330, \"train_examples_seen\": 197330, \"impatience\": 1, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  4.79it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 600, \"metrics\": {\"ner_f1\": 99.3283, \"ner_token_f1\": 99.6985}, \"time_spent\": \"0:05:08\", \"epochs_done\": 5, \"batches_seen\": 340, \"train_examples_seen\": 203330, \"loss\": 0.019688239507377147}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "15it [00:02,  7.44it/s]\n",
      "2025-09-28 13:47:43.664 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 90.4282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 8721, \"metrics\": {\"ner_f1\": 89.8439, \"ner_token_f1\": 92.6428}, \"time_spent\": \"0:05:10\", \"epochs_done\": 5, \"batches_seen\": 340, \"train_examples_seen\": 203330, \"impatience\": 2, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "58it [00:40,  1.45it/s]\n",
      "1it [00:00,  3.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 600, \"metrics\": {\"ner_f1\": 99.2305, \"ner_token_f1\": 99.4521}, \"time_spent\": \"0:05:15\", \"epochs_done\": 6, \"batches_seen\": 350, \"train_examples_seen\": 209196, \"loss\": 0.019872820097953083}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "15it [00:02,  7.44it/s]\n",
      "2025-09-28 13:47:50.255 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 90.4282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 8721, \"metrics\": {\"ner_f1\": 89.4169, \"ner_token_f1\": 92.2704}, \"time_spent\": \"0:05:17\", \"epochs_done\": 6, \"batches_seen\": 350, \"train_examples_seen\": 209196, \"impatience\": 3, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  4.84it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 600, \"metrics\": {\"ner_f1\": 98.9756, \"ner_token_f1\": 99.5691}, \"time_spent\": \"0:05:21\", \"epochs_done\": 6, \"batches_seen\": 360, \"train_examples_seen\": 215196, \"loss\": 0.01663473341614008}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "15it [00:02,  6.47it/s]\n",
      "2025-09-28 13:47:57.14 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 90.4282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 8721, \"metrics\": {\"ner_f1\": 89.8621, \"ner_token_f1\": 92.5353}, \"time_spent\": \"0:05:24\", \"epochs_done\": 6, \"batches_seen\": 360, \"train_examples_seen\": 215196, \"impatience\": 4, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  4.75it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 600, \"metrics\": {\"ner_f1\": 99.6276, \"ner_token_f1\": 99.7534}, \"time_spent\": \"0:05:28\", \"epochs_done\": 6, \"batches_seen\": 370, \"train_examples_seen\": 221196, \"loss\": 0.01560615822672844}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "15it [00:02,  7.45it/s]\n",
      "2025-09-28 13:48:03.702 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 90.4282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 8721, \"metrics\": {\"ner_f1\": 89.9792, \"ner_token_f1\": 92.6504}, \"time_spent\": \"0:05:30\", \"epochs_done\": 6, \"batches_seen\": 370, \"train_examples_seen\": 221196, \"impatience\": 5, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  4.89it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 600, \"metrics\": {\"ner_f1\": 98.8569, \"ner_token_f1\": 99.2913}, \"time_spent\": \"0:05:35\", \"epochs_done\": 6, \"batches_seen\": 380, \"train_examples_seen\": 227196, \"loss\": 0.01563425874337554}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "15it [00:02,  6.86it/s]\n",
      "2025-09-28 13:48:10.318 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 90.4282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 8721, \"metrics\": {\"ner_f1\": 90.2023, \"ner_token_f1\": 92.8216}, \"time_spent\": \"0:05:37\", \"epochs_done\": 6, \"batches_seen\": 380, \"train_examples_seen\": 227196, \"impatience\": 6, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  4.24it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 600, \"metrics\": {\"ner_f1\": 99.6782, \"ner_token_f1\": 99.7636}, \"time_spent\": \"0:05:42\", \"epochs_done\": 6, \"batches_seen\": 390, \"train_examples_seen\": 233196, \"loss\": 0.015839336439967155}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "15it [00:02,  7.18it/s]\n",
      "2025-09-28 13:48:17.75 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 206: Improved best ner_f1 from 90.4282 to 90.5197\n",
      "2025-09-28 13:48:17.76 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 208: Saving model\n",
      "2025-09-28 13:48:17.77 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 175: Saving model to C:\\Users\\lexan\\OneDrive\\Documents\\hackaton_lct\\models\\model.pth.tar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 8721, \"metrics\": {\"ner_f1\": 90.5197, \"ner_token_f1\": 93.0718}, \"time_spent\": \"0:05:44\", \"epochs_done\": 6, \"batches_seen\": 390, \"train_examples_seen\": 233196, \"impatience\": 0, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  3.71it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 600, \"metrics\": {\"ner_f1\": 98.4188, \"ner_token_f1\": 99.5383}, \"time_spent\": \"0:05:56\", \"epochs_done\": 6, \"batches_seen\": 400, \"train_examples_seen\": 239196, \"loss\": 0.017159743793308736}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "15it [00:02,  7.32it/s]\n",
      "2025-09-28 13:48:31.638 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 90.5197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 8721, \"metrics\": {\"ner_f1\": 90.2608, \"ner_token_f1\": 92.8339}, \"time_spent\": \"0:05:58\", \"epochs_done\": 6, \"batches_seen\": 400, \"train_examples_seen\": 239196, \"impatience\": 1, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "58it [00:46,  1.24it/s]\n",
      "1it [00:00,  4.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 600, \"metrics\": {\"ner_f1\": 99.5644, \"ner_token_f1\": 99.7672}, \"time_spent\": \"0:06:02\", \"epochs_done\": 7, \"batches_seen\": 410, \"train_examples_seen\": 245062, \"loss\": 0.01573817925527692}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "15it [00:02,  7.08it/s]\n",
      "2025-09-28 13:48:38.9 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 90.5197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 8721, \"metrics\": {\"ner_f1\": 89.9727, \"ner_token_f1\": 92.6024}, \"time_spent\": \"0:06:05\", \"epochs_done\": 7, \"batches_seen\": 410, \"train_examples_seen\": 245062, \"impatience\": 2, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  4.73it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 600, \"metrics\": {\"ner_f1\": 99.6025, \"ner_token_f1\": 99.6608}, \"time_spent\": \"0:06:09\", \"epochs_done\": 7, \"batches_seen\": 420, \"train_examples_seen\": 251062, \"loss\": 0.014492714311927557}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "15it [00:01,  7.64it/s]\n",
      "2025-09-28 13:48:44.68 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 90.5197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 8721, \"metrics\": {\"ner_f1\": 90.0973, \"ner_token_f1\": 92.7416}, \"time_spent\": \"0:06:11\", \"epochs_done\": 7, \"batches_seen\": 420, \"train_examples_seen\": 251062, \"impatience\": 3, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  5.00it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 600, \"metrics\": {\"ner_f1\": 99.2647, \"ner_token_f1\": 99.3733}, \"time_spent\": \"0:06:15\", \"epochs_done\": 7, \"batches_seen\": 430, \"train_examples_seen\": 257062, \"loss\": 0.013354893494397401}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "15it [00:02,  7.13it/s]\n",
      "2025-09-28 13:48:50.230 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 90.5197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 8721, \"metrics\": {\"ner_f1\": 90.0806, \"ner_token_f1\": 92.8184}, \"time_spent\": \"0:06:17\", \"epochs_done\": 7, \"batches_seen\": 430, \"train_examples_seen\": 257062, \"impatience\": 4, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  4.54it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 600, \"metrics\": {\"ner_f1\": 99.721, \"ner_token_f1\": 99.7972}, \"time_spent\": \"0:06:21\", \"epochs_done\": 7, \"batches_seen\": 440, \"train_examples_seen\": 263062, \"loss\": 0.015584207884967328}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "15it [00:02,  7.25it/s]\n",
      "2025-09-28 13:48:56.487 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 90.5197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 8721, \"metrics\": {\"ner_f1\": 89.7267, \"ner_token_f1\": 92.435}, \"time_spent\": \"0:06:23\", \"epochs_done\": 7, \"batches_seen\": 440, \"train_examples_seen\": 263062, \"impatience\": 5, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  2.26it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 600, \"metrics\": {\"ner_f1\": 98.2017, \"ner_token_f1\": 99.5389}, \"time_spent\": \"0:06:28\", \"epochs_done\": 7, \"batches_seen\": 450, \"train_examples_seen\": 269062, \"loss\": 0.01398715954273939}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "15it [00:02,  7.36it/s]\n",
      "2025-09-28 13:49:03.462 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 90.5197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 8721, \"metrics\": {\"ner_f1\": 89.9772, \"ner_token_f1\": 92.6913}, \"time_spent\": \"0:06:30\", \"epochs_done\": 7, \"batches_seen\": 450, \"train_examples_seen\": 269062, \"impatience\": 6, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  4.37it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 600, \"metrics\": {\"ner_f1\": 99.273, \"ner_token_f1\": 99.4208}, \"time_spent\": \"0:06:35\", \"epochs_done\": 7, \"batches_seen\": 460, \"train_examples_seen\": 275062, \"loss\": 0.01526748538017273}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "15it [00:02,  6.79it/s]\n",
      "2025-09-28 13:49:10.261 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 90.5197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 8721, \"metrics\": {\"ner_f1\": 90.0504, \"ner_token_f1\": 92.7675}, \"time_spent\": \"0:06:37\", \"epochs_done\": 7, \"batches_seen\": 460, \"train_examples_seen\": 275062, \"impatience\": 7, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "58it [00:37,  1.53it/s]\n",
      "1it [00:00,  4.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 600, \"metrics\": {\"ner_f1\": 96.2205, \"ner_token_f1\": 99.4598}, \"time_spent\": \"0:06:41\", \"epochs_done\": 8, \"batches_seen\": 470, \"train_examples_seen\": 280928, \"loss\": 0.014195829350501298}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "15it [00:02,  7.28it/s]\n",
      "2025-09-28 13:49:16.792 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 90.5197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 8721, \"metrics\": {\"ner_f1\": 90.4076, \"ner_token_f1\": 93.1335}, \"time_spent\": \"0:06:44\", \"epochs_done\": 8, \"batches_seen\": 470, \"train_examples_seen\": 280928, \"impatience\": 8, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  4.19it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 600, \"metrics\": {\"ner_f1\": 98.9028, \"ner_token_f1\": 99.7367}, \"time_spent\": \"0:06:48\", \"epochs_done\": 8, \"batches_seen\": 480, \"train_examples_seen\": 286928, \"loss\": 0.013487676624208689}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "15it [00:02,  6.63it/s]\n",
      "2025-09-28 13:49:23.564 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 90.5197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 8721, \"metrics\": {\"ner_f1\": 89.8072, \"ner_token_f1\": 92.5682}, \"time_spent\": \"0:06:50\", \"epochs_done\": 8, \"batches_seen\": 480, \"train_examples_seen\": 286928, \"impatience\": 9, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  4.25it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 600, \"metrics\": {\"ner_f1\": 99.6488, \"ner_token_f1\": 99.7672}, \"time_spent\": \"0:06:55\", \"epochs_done\": 8, \"batches_seen\": 490, \"train_examples_seen\": 292928, \"loss\": 0.012370779272168874}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "15it [00:02,  7.21it/s]\n",
      "2025-09-28 13:49:30.376 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 90.5197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 8721, \"metrics\": {\"ner_f1\": 90.0431, \"ner_token_f1\": 92.6134}, \"time_spent\": \"0:06:57\", \"epochs_done\": 8, \"batches_seen\": 490, \"train_examples_seen\": 292928, \"impatience\": 10, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  4.30it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 600, \"metrics\": {\"ner_f1\": 99.7608, \"ner_token_f1\": 99.8}, \"time_spent\": \"0:07:02\", \"epochs_done\": 8, \"batches_seen\": 500, \"train_examples_seen\": 298928, \"loss\": 0.011709695309400558}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "15it [00:02,  6.98it/s]\n",
      "2025-09-28 13:49:37.302 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 90.5197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 8721, \"metrics\": {\"ner_f1\": 90.327, \"ner_token_f1\": 92.9429}, \"time_spent\": \"0:07:04\", \"epochs_done\": 8, \"batches_seen\": 500, \"train_examples_seen\": 298928, \"impatience\": 11, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  4.23it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 600, \"metrics\": {\"ner_f1\": 99.6154, \"ner_token_f1\": 99.7149}, \"time_spent\": \"0:07:08\", \"epochs_done\": 8, \"batches_seen\": 510, \"train_examples_seen\": 304928, \"loss\": 0.01285783452913165}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "15it [00:01,  7.57it/s]\n",
      "2025-09-28 13:49:43.637 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 90.5197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 8721, \"metrics\": {\"ner_f1\": 90.2766, \"ner_token_f1\": 92.7754}, \"time_spent\": \"0:07:10\", \"epochs_done\": 8, \"batches_seen\": 510, \"train_examples_seen\": 304928, \"impatience\": 12, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  4.33it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 600, \"metrics\": {\"ner_f1\": 98.3711, \"ner_token_f1\": 99.7634}, \"time_spent\": \"0:07:14\", \"epochs_done\": 8, \"batches_seen\": 520, \"train_examples_seen\": 310928, \"loss\": 0.012930790986865759}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "15it [00:02,  6.89it/s]\n",
      "2025-09-28 13:49:49.965 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 90.5197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 8721, \"metrics\": {\"ner_f1\": 90.0247, \"ner_token_f1\": 92.7292}, \"time_spent\": \"0:07:17\", \"epochs_done\": 8, \"batches_seen\": 520, \"train_examples_seen\": 310928, \"impatience\": 13, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "58it [00:38,  1.49it/s]\n",
      "1it [00:00,  3.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 600, \"metrics\": {\"ner_f1\": 99.6421, \"ner_token_f1\": 99.631}, \"time_spent\": \"0:07:21\", \"epochs_done\": 9, \"batches_seen\": 530, \"train_examples_seen\": 316794, \"loss\": 0.012003397475928069}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "15it [00:01,  7.62it/s]\n",
      "2025-09-28 13:49:56.405 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 90.5197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 8721, \"metrics\": {\"ner_f1\": 90.0401, \"ner_token_f1\": 92.7652}, \"time_spent\": \"0:07:23\", \"epochs_done\": 9, \"batches_seen\": 530, \"train_examples_seen\": 316794, \"impatience\": 14, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  4.35it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 600, \"metrics\": {\"ner_f1\": 95.8529, \"ner_token_f1\": 99.7292}, \"time_spent\": \"0:07:28\", \"epochs_done\": 9, \"batches_seen\": 540, \"train_examples_seen\": 322794, \"loss\": 0.011909008584916591}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "15it [00:01,  7.55it/s]\n",
      "2025-09-28 13:50:03.3 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 90.5197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 8721, \"metrics\": {\"ner_f1\": 90.1436, \"ner_token_f1\": 92.8753}, \"time_spent\": \"0:07:30\", \"epochs_done\": 9, \"batches_seen\": 540, \"train_examples_seen\": 322794, \"impatience\": 15, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  3.55it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 600, \"metrics\": {\"ner_f1\": 99.8841, \"ner_token_f1\": 99.9039}, \"time_spent\": \"0:07:34\", \"epochs_done\": 9, \"batches_seen\": 550, \"train_examples_seen\": 328794, \"loss\": 0.011506815720349551}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "15it [00:02,  5.93it/s]\n",
      "2025-09-28 13:50:10.12 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 90.5197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 8721, \"metrics\": {\"ner_f1\": 89.8942, \"ner_token_f1\": 92.5388}, \"time_spent\": \"0:07:37\", \"epochs_done\": 9, \"batches_seen\": 550, \"train_examples_seen\": 328794, \"impatience\": 16, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  4.80it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 600, \"metrics\": {\"ner_f1\": 95.7532, \"ner_token_f1\": 99.7602}, \"time_spent\": \"0:07:41\", \"epochs_done\": 9, \"batches_seen\": 560, \"train_examples_seen\": 334794, \"loss\": 0.010416795872151852}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "15it [00:01,  7.64it/s]\n",
      "2025-09-28 13:50:16.664 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 90.5197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 8721, \"metrics\": {\"ner_f1\": 89.5708, \"ner_token_f1\": 92.3659}, \"time_spent\": \"0:07:43\", \"epochs_done\": 9, \"batches_seen\": 560, \"train_examples_seen\": 334794, \"impatience\": 17, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  5.73it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 600, \"metrics\": {\"ner_f1\": 99.8377, \"ner_token_f1\": 99.8639}, \"time_spent\": \"0:07:47\", \"epochs_done\": 9, \"batches_seen\": 570, \"train_examples_seen\": 340794, \"loss\": 0.011447818949818611}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "15it [00:02,  7.00it/s]\n",
      "2025-09-28 13:50:22.912 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 90.5197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 8721, \"metrics\": {\"ner_f1\": 89.517, \"ner_token_f1\": 92.2178}, \"time_spent\": \"0:07:50\", \"epochs_done\": 9, \"batches_seen\": 570, \"train_examples_seen\": 340794, \"impatience\": 18, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  5.25it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 600, \"metrics\": {\"ner_f1\": 95.5927, \"ner_token_f1\": 99.8369}, \"time_spent\": \"0:07:53\", \"epochs_done\": 9, \"batches_seen\": 580, \"train_examples_seen\": 346660, \"loss\": 0.012583469599485397}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "15it [00:01,  7.73it/s]\n",
      "2025-09-28 13:50:28.685 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 90.5197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 8721, \"metrics\": {\"ner_f1\": 90.1907, \"ner_token_f1\": 92.8301}, \"time_spent\": \"0:07:55\", \"epochs_done\": 9, \"batches_seen\": 580, \"train_examples_seen\": 346660, \"impatience\": 19, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "58it [00:37,  1.53it/s]\n",
      "1it [00:00,  4.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 600, \"metrics\": {\"ner_f1\": 99.8002, \"ner_token_f1\": 99.7951}, \"time_spent\": \"0:07:59\", \"epochs_done\": 10, \"batches_seen\": 590, \"train_examples_seen\": 352660, \"loss\": 0.010964993806555867}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "15it [00:02,  7.19it/s]\n",
      "2025-09-28 13:50:34.835 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 90.5197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 8721, \"metrics\": {\"ner_f1\": 90.1198, \"ner_token_f1\": 92.7738}, \"time_spent\": \"0:08:02\", \"epochs_done\": 10, \"batches_seen\": 590, \"train_examples_seen\": 352660, \"impatience\": 20, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  4.64it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 600, \"metrics\": {\"ner_f1\": 99.797, \"ner_token_f1\": 99.8293}, \"time_spent\": \"0:08:06\", \"epochs_done\": 10, \"batches_seen\": 600, \"train_examples_seen\": 358660, \"loss\": 0.010401354730129242}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "15it [00:01,  7.61it/s]\n",
      "2025-09-28 13:50:40.919 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 90.5197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 8721, \"metrics\": {\"ner_f1\": 90.0716, \"ner_token_f1\": 92.724}, \"time_spent\": \"0:08:08\", \"epochs_done\": 10, \"batches_seen\": 600, \"train_examples_seen\": 358660, \"impatience\": 21, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  2.37it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 600, \"metrics\": {\"ner_f1\": 96.4371, \"ner_token_f1\": 100.0}, \"time_spent\": \"0:08:12\", \"epochs_done\": 10, \"batches_seen\": 610, \"train_examples_seen\": 364660, \"loss\": 0.009850841388106346}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "15it [00:01,  7.84it/s]\n",
      "2025-09-28 13:50:47.282 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 90.5197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 8721, \"metrics\": {\"ner_f1\": 89.3948, \"ner_token_f1\": 92.1831}, \"time_spent\": \"0:08:14\", \"epochs_done\": 10, \"batches_seen\": 610, \"train_examples_seen\": 364660, \"impatience\": 22, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  5.84it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 600, \"metrics\": {\"ner_f1\": 99.8777, \"ner_token_f1\": 99.8971}, \"time_spent\": \"0:08:18\", \"epochs_done\": 10, \"batches_seen\": 620, \"train_examples_seen\": 370660, \"loss\": 0.011373198591172695}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "15it [00:01,  7.68it/s]\n",
      "2025-09-28 13:50:53.265 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 90.5197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 8721, \"metrics\": {\"ner_f1\": 89.9823, \"ner_token_f1\": 92.6157}, \"time_spent\": \"0:08:20\", \"epochs_done\": 10, \"batches_seen\": 620, \"train_examples_seen\": 370660, \"impatience\": 23, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  5.33it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 600, \"metrics\": {\"ner_f1\": 94.6688, \"ner_token_f1\": 99.7965}, \"time_spent\": \"0:08:24\", \"epochs_done\": 10, \"batches_seen\": 630, \"train_examples_seen\": 376660, \"loss\": 0.011395141249522567}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "15it [00:01,  7.69it/s]\n",
      "2025-09-28 13:50:59.535 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 90.5197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 8721, \"metrics\": {\"ner_f1\": 90.0773, \"ner_token_f1\": 92.7956}, \"time_spent\": \"0:08:26\", \"epochs_done\": 10, \"batches_seen\": 630, \"train_examples_seen\": 376660, \"impatience\": 24, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "58it [00:33,  1.71it/s]\n",
      "1it [00:00,  4.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 600, \"metrics\": {\"ner_f1\": 99.8416, \"ner_token_f1\": 99.967}, \"time_spent\": \"0:08:30\", \"epochs_done\": 11, \"batches_seen\": 640, \"train_examples_seen\": 382526, \"loss\": 0.010351166315376758}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "15it [00:02,  6.90it/s]\n",
      "2025-09-28 13:51:06.2 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 90.5197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 8721, \"metrics\": {\"ner_f1\": 89.612, \"ner_token_f1\": 92.3469}, \"time_spent\": \"0:08:33\", \"epochs_done\": 11, \"batches_seen\": 640, \"train_examples_seen\": 382526, \"impatience\": 25, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  5.90it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 600, \"metrics\": {\"ner_f1\": 99.9196, \"ner_token_f1\": 99.9316}, \"time_spent\": \"0:08:37\", \"epochs_done\": 11, \"batches_seen\": 650, \"train_examples_seen\": 388526, \"loss\": 0.00990659836679697}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "4it [00:00,  5.98it/s]\n",
      "11it [00:07,  1.38it/s]\n",
      "2025-09-28 13:51:10.600 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 336: Stopped training\n",
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "15it [00:02,  6.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 8721, \"metrics\": {\"ner_f1\": 90.5197, \"ner_token_f1\": 93.0718}, \"time_spent\": \"0:00:03\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00,  7.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"test\": {\"eval_examples_count\": 2180, \"metrics\": {\"ner_f1\": 92.6228, \"ner_token_f1\": 94.4444}, \"time_spent\": \"0:00:01\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ner_model = train_model(model_config, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c25a8b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset_reader': {'class_name': 'conll2003_reader',\n",
       "  'data_path': '../datasets/conll/',\n",
       "  'dataset_name': 'collection3',\n",
       "  'provide_pos': False,\n",
       "  'provide_chunk': False,\n",
       "  'iobes': True},\n",
       " 'dataset_iterator': {'class_name': 'data_learning_iterator'},\n",
       " 'chainer': {'in': ['x'],\n",
       "  'in_y': ['y'],\n",
       "  'pipe': [{'class_name': 'torch_transformers_ner_preprocessor',\n",
       "    'vocab_file': 'DeepPavlov/rubert-base-cased',\n",
       "    'do_lower_case': False,\n",
       "    'max_seq_length': 512,\n",
       "    'max_subword_length': 15,\n",
       "    'token_masking_prob': 0.0,\n",
       "    'in': ['x'],\n",
       "    'out': ['x_tokens',\n",
       "     'x_subword_tokens',\n",
       "     'x_subword_tok_ids',\n",
       "     'startofword_markers',\n",
       "     'attention_mask',\n",
       "     'tokens_offsets']},\n",
       "   {'id': 'tag_vocab',\n",
       "    'class_name': 'simple_vocab',\n",
       "    'unk_token': ['O'],\n",
       "    'pad_with_zeros': True,\n",
       "    'save_path': '../models/tag.dict',\n",
       "    'load_path': '../models/tag.dict',\n",
       "    'fit_on': ['y'],\n",
       "    'in': ['y'],\n",
       "    'out': ['y_ind']},\n",
       "   {'class_name': 'torch_transformers_sequence_tagger',\n",
       "    'n_tags': '#tag_vocab.len',\n",
       "    'pretrained_bert': 'DeepPavlov/rubert-base-cased',\n",
       "    'attention_probs_keep_prob': 0.5,\n",
       "    'encoder_layer_ids': [-1],\n",
       "    'optimizer': 'AdamW',\n",
       "    'optimizer_parameters': {'lr': 2e-05,\n",
       "     'weight_decay': 1e-06,\n",
       "     'betas': [0.9, 0.999],\n",
       "     'eps': 1e-06},\n",
       "    'clip_norm': 1.0,\n",
       "    'min_learning_rate': 1e-07,\n",
       "    'learning_rate_drop_patience': 30,\n",
       "    'learning_rate_drop_div': 1.5,\n",
       "    'load_before_drop': True,\n",
       "    'save_path': '../models',\n",
       "    'load_path': '../models',\n",
       "    'in': ['x_subword_tok_ids', 'attention_mask', 'startofword_markers'],\n",
       "    'in_y': ['y_ind'],\n",
       "    'out': ['y_pred_ind', 'probas']},\n",
       "   {'ref': 'tag_vocab', 'in': ['y_pred_ind'], 'out': ['y_pred']}],\n",
       "  'out': ['x_tokens', 'y_pred']},\n",
       " 'train': {'epochs': 30,\n",
       "  'batch_size': 14,\n",
       "  'metrics': [{'name': 'ner_f1', 'inputs': ['y', 'y_pred']},\n",
       "   {'name': 'ner_token_f1', 'inputs': ['y', 'y_pred']}],\n",
       "  'validation_patience': 100,\n",
       "  'val_every_n_batches': 20,\n",
       "  'log_every_n_batches': 20,\n",
       "  'show_examples': False,\n",
       "  'pytest_max_batches': 2,\n",
       "  'pytest_batch_size': 8,\n",
       "  'evaluation_targets': ['valid', 'test'],\n",
       "  'class_name': 'torch_trainer'},\n",
       " 'metadata': {'variables': {'ROOT_PATH': '~/.deeppavlov',\n",
       "   'DOWNLOADS_PATH': '~/.deeppavlov/downloads',\n",
       "   'MODELS_PATH': '~/.deeppavlov/models',\n",
       "   'TRANSFORMER': 'DeepPavlov/rubert-base-cased',\n",
       "   'MODEL_PATH': '../models'},\n",
       "  'requirements': ['c:\\\\Users\\\\lexan\\\\miniconda3\\\\envs\\\\dp310\\\\lib\\\\site-packages\\\\deeppavlov/requirements/transformers.txt',\n",
       "   'c:\\\\Users\\\\lexan\\\\miniconda3\\\\envs\\\\dp310\\\\lib\\\\site-packages\\\\deeppavlov/requirements/pytorch.txt',\n",
       "   'c:\\\\Users\\\\lexan\\\\miniconda3\\\\envs\\\\dp310\\\\lib\\\\site-packages\\\\deeppavlov/requirements/torchcrf.txt',\n",
       "   'c:\\\\Users\\\\lexan\\\\miniconda3\\\\envs\\\\dp310\\\\lib\\\\site-packages\\\\deeppavlov/requirements/sentencepiece.txt',\n",
       "   'c:\\\\Users\\\\lexan\\\\miniconda3\\\\envs\\\\dp310\\\\lib\\\\site-packages\\\\deeppavlov/requirements/protobuf.txt']}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e399f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca8fc0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lexan\\miniconda3\\envs\\dp310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\lexan\\miniconda3\\envs\\dp310\\lib\\site-packages\\huggingface_hub\\file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from deeppavlov import build_model\n",
    "\n",
    "ner_model = build_model(model_config, download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e346a202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['artfruit', 'нектари']], [['S-BRAND', 'S-TYPE']]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_model(['artfruit нектари'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4d8fee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dp310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
